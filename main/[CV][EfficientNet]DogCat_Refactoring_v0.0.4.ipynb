{"cells":[{"cell_type":"markdown","metadata":{"id":"TP-hVDfx4WWI"},"source":["# **Title Name :  개 VS 고양이 이진분류**\n","\n","<p style=\"font-weight:bolder; font-size : 21px\">\n","   RegDate : 2023.12.18\n","<p>\n","\n","------------------------------------------------------------"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"O0-Smujn4WWL"},"outputs":[],"source":["#===============================================================================\n","#                               초기 입력값 설문조사\n","#===============================================================================\n","\n","# ▶ 프로젝트의 카테고리는?\n","PROJECT_CATEGORY = 'classification'\n","\n","# ▶ 프로젝트 파일의 버전은?\n","MODELING_VERSION = 'v0.0.3'\n","\n","# ▶ 사용할 모델은?\n","MODEL_NAME = 'efficientnet_b4'\n","\n","# ▶ Batch 를 몇으로 지정할까요?\n","BATCH = 32\n","\n","# ▶ Epochs를 몇으로 지정할까요?\n","EPOCHS = 100\n","\n","# [!]압축이 필요한 데이터셋입니까?\n","NEED_UNZIP = True\n","\n","# [!]루트경로에 압축을 해제합니까? (코랩전용 : 단발성)\n","UNZIP_TO_ROOT = True\n","\n","#======[옵션]=========================================================================\n","\n","# ▶ 현재 코랩 폴더경로를 복사합니까?(코랩용 : 자동설정 //안쓸경우 주석처리)\n","COPY_CURRENT_FOLDER_PATH_FOR_COLAB = \\\n","'/content/drive/MyDrive/프로젝트/[CV]개&고양이 분류/'\n","\n","# ▶ 현재 캐글 대회 주소를 복사합니까?(캐글용 : 자동설정 //안쓸경우 주석처리)\n","COPY_CURRENT_COMPETITIONS_URL_FOR_KAGGLE = \\\n","'https://www.kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition'\n","#===============================================================================\n","#  ⬇⬇⬇ 설문의 상세설명이 필요하다면 `최하단` 부록1의 설명참고 ⬇⬇⬇"]},{"cell_type":"markdown","metadata":{"id":"x0HY5J8X4WWN"},"source":["# 1. 환경설정\n","-------------"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"P49AJSjr4WWN"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\anaconda3\\envs\\DL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","c:\\anaconda3\\envs\\DL\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  _torch_pytree._register_pytree_node(\n"]}],"source":["#===============================================================================\n","# ▶ [모듈] 불러오기\n","#===============================================================================\n","\n","# 시스템\n","import os\n","import sys\n","import random\n","from glob import glob\n","from time import time\n","\n","# 데이터분석\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","#이미지작업\n","from PIL import Image\n","import cv2\n","\n","# 파이토치\n","from torch import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader , Dataset ,ConcatDataset, random_split\n","from torchsummary import summary\n","from torch.autograd import Variable\n","\n","# CV용 토치비전\n","import torchvision\n","from torchvision.transforms import transforms\n","\n","# 전이학습\n","import torchvision.models as models\n","\n","\n","# 사이킷런\n","import sklearn\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.model_selection import GroupKFold, train_test_split\n","\n","\n","# 유틸\n","import gc\n","import psutil\n","from tqdm.auto import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# 기타추가옵션\n","import copy\n","import zipfile\n","\n","# 시각화테마\n","sns.set_style(style='white')\n","plt.style.use('dark_background')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"OEy04Evv4WWO"},"outputs":[],"source":["#===============================================================================\n","# ▶ [트리거] 설정모음\n","#===============================================================================\n","IS_GOOGLE = True if 'google.colab'                 in sys.modules   else False\n","IS_KAGGLE = True if 'KAGGLE_KERNEL_RUN_TYPE'       in os.environ    else False\n","IS_LOCAL  = True if  not (IS_GOOGLE or IS_KAGGLE)                   else False"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"LHYNeDAU4WWO"},"outputs":[],"source":["#===============================================================================\n","# ▶ [에러] 설정모음\n","#===============================================================================\n","class ModelNotFoundError(Exception):\n","    def __init__(self, model_name):\n","        self.model_name = model_name\n","        self.message = f\"Model '{model_name}'을 찾을 수 없습니다. \\\n","                         필요하다면 사전에 추가하거나 오탈자를 확인하세요.\"\n","        super().__init__(self.message)\n","    def __str__(self):\n","        return self.message\n","\n","class ZipFileNotFoundError(Exception):\n","    def __init__(self, base_path):\n","        self.base_path = base_path\n","        self.message = f\"'{base_path}' 경로에 압축 파일이 없거나,\\\n","                          지원하지 않는 확장자입니다.\"\n","        super().__init__(self.message)\n","\n","    def __str__(self):\n","        return self.message"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"NhAuAPIKdgDe"},"outputs":[],"source":["#===============================================================================\n","# ▶ [폴더경로] 설정모음\n","#===============================================================================\n","class Directory():\n","\n","    def __init__(self):\n","        self._creat_working_folders = None\n","        self._root_path = None\n","        self._working_path = None\n","        self._temp_path = None\n","        self._save_path = None\n","        self._base_path = None\n","        self._unzip_path = None\n","        self._zip_path = None\n","        self._train_path = None\n","        self._test_path = None\n","        self._save_model_pt = None\n","        self._save_submission_csv = None\n","        self._save_model_pt_by_10_epoch_in_temp = None\n","        self.copied_raw_path  = COPY_CURRENT_FOLDER_PATH_FOR_COLAB \\\n","            if IS_GOOGLE else COPY_CURRENT_COMPETITIONS_URL_FOR_KAGGLE \\\n","            if IS_KAGGLE else None\n","\n","\n","    @property\n","    def creat_working_folders(self):\n","        if self._creat_working_folders is None:\n","            self._creat_working_folders = create_working_folders(self.working_path)\n","        return self._creat_working_folders\n","\n","\n","    @property\n","    def root_path(self):\n","        if self._root_path is None:\n","            self._root_path = get_root_path()\n","        return self._root_path\n","\n","    @property\n","    def working_path(self):\n","        if self._working_path is None:\n","            self._working_path = get_working_path()\n","        return self._working_path\n","\n","    @property\n","    def temp_path(self):\n","        if self._temp_path is None:\n","            self._temp_path = get_temp_path(self.working_path)\n","        return self._temp_path\n","\n","    @property\n","    def save_path(self):\n","        if self._save_path is None:\n","            self._save_path = get_save_path(self.working_path)\n","        return self._save_path\n","\n","    @property\n","    def base_path(self):\n","        if self._base_path is None:\n","            self._base_path = get_base_path(self.working_path)\n","        return self._base_path\n","\n","    @property\n","    def unzip_path(self):\n","        if self._unzip_path is None:\n","            self._unzip_path = get_unzip_path()\n","        return self._unzip_path\n","\n","    @property\n","    def zip_path(self):\n","        if self._zip_path is None:\n","            self._zip_path = get_zip_path(self.working_path)\n","        return self._zip_path\n","\n","    @property\n","    def train_path(self):\n","        if self._train_path is None:\n","            self._train_path = get_train_path(self.working_path)\n","        return self._train_path\n","\n","    @property\n","    def test_path(self):\n","        if self._test_path is None:\n","            self._test_path = get_test_path(self.working_path)\n","        return self._test_path\n","\n","    @property\n","    def save_model_pt(self):\n","        if self._save_model_pt is None:\n","            self._save_model_pt = f'[Category_{PROJECT_CATEGORY}]EPC{EPOCHS}_BAT{BATCH}_{MODEL_NAME}_{MODELING_VERSION}.pt'\n","        return self._save_model_pt\n","\n","    @property\n","    def save_model_pt_by_10_epoch_in_temp(self):\n","        if self._save_model_pt_by_10_epoch_in_temp is None:\n","            self._save_model_pt_by_10_epoch_in_temp = f'EPC{EPOCHS}_BAT{BATCH}_{MODEL_NAME}_{MODELING_VERSION}.pt'\n","        return self._save_model_pt_by_10_epoch_in_temp\n","\n","    @property\n","    def save_submission_csv(self):\n","        if self._save_submission_csv is None:\n","            self._save_submission_csv = f'[Category_{PROJECT_CATEGORY}]EPC{EPOCHS}_BAT{BATCH}_{MODEL_NAME}_Submission.csv'\n","        return self._save_submission_csv\n","# 객체인스턴스생성\n","directory = Directory()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"S-1ia1FDelzm"},"outputs":[],"source":["#===============================================================================\n","# ▶ [딕셔너리] 설정모음\n","#===============================================================================\n","class Dict():\n","    def __init__(self):\n","        self.dictionary = None\n","\n","    @property\n","    def train_path(self):\n","        if self.dictionary is None:\n","            self.dictionary =\\\n","            {\n","                'zipfiles': ['train.zip', 'test.zip'],\n","            }\n","        return self.dictionary\n","# 객체인스턴스생성\n","dictionary = Dict()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"V3W_RY5J4WWO"},"outputs":[],"source":["#===============================================================================\n","# ▶ [유틸함수] 설정모음\n","#===============================================================================\n","# 구분자설정\n","def get_seperater() :\n","    return os.path.sep\n","\n","\n","# 라이브러리 설치 설정(코랩,캐글)\n","def install_modules() :\n","    if not IS_LOCAL :\n","        '''\n","        ⬇⬇⬇설치할 라이브러리를 추가⬇⬇⬇\n","        '''\n","        !pip install -qqq timm\n","        !pip install -qqq efficientnet_pytorch\n","        import timm\n","        import efficientnet_pytorch\n","        print('module install complete')\n","\n","# 코랩 마운트설정\n","def mount_colab() :\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","\n","\n","\n","\n","# 루트경로설정(코랩용)\n","def get_root_path() :\n","    if IS_GOOGLE :\n","        root_path = '/content/'\n","        return root_path\n","    pass\n","\n","# 작업장 경로설정\n","def get_working_path() :\n","    copied_raw_path = directory.copied_raw_path\n","    print(copied_raw_path)\n","    # 코랩용\n","    if IS_GOOGLE:\n","        mount_colab()\n","        parent_path_name = copied_raw_path.split('MyDrive')[1].split('/')[1]\n","        project_name = copied_raw_path.split('MyDrive')[1].split('/')[2]\n","        working_path = f'/content/drive/MyDrive/{parent_path_name}/{project_name}'\n","    # 캐글용\n","    elif IS_KAGGLE :\n","        project_name = copied_raw_path.split('competitions')[1].split('/')[1]\n","        working_path = f'/kaggle/input/{project_name}'\n","    # 로컬용\n","    elif IS_LOCAL :\n","        # working_path = os.getcwd() # 절대경로로 표시됨\n","        # working_path = './'        # .//data 형태로표시되서 에러발생할수도있음\n","        working_path = os.path.relpath(os.getcwd()) # '.' 만 출력 './data 형태로 표시됨\n","    return working_path\n","\n","\n","# 작업장 폴더생성\n","def create_working_folders(working_path):\n","    current_directory = working_path\n","    folders_to_check = ['save', 'temp', 'data']\n","\n","    for folder_name in folders_to_check:\n","        folder_path = os.path.join(current_directory, folder_name)\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","            print(f\"폴더 생성 완료 : {folder_path}\")\n","        else:\n","            print(f\"폴더가 이미 존재합니다: {folder_path}\")\n","\n","# 데이터 경로설정\n","def get_base_path(working_path) :\n","    sep = get_seperater()\n","    return working_path + f'{sep}data{sep}'\n","\n","# 저장용 경로설정\n","def get_save_path(working_path) :\n","    sep = get_seperater()\n","    return working_path + f'{sep}save{sep}'\n","\n","# 임시용 경로설정\n","def get_temp_path(working_path) :\n","    sep = get_seperater()\n","    return working_path + f'{sep}temp{sep}'\n","\n","# 압축파일 경로설정\n","def get_zip_path(working_path) :\n","    base_path = get_base_path(working_path)\n","    # 폴더에 압축파일이 없다면, 예외처리\n","    if not has_zipfile_in(base_path):\n","        base_path = None\n","        raise ZipFileNotFoundError(base_path)\n","    return base_path\n","\n","# 압축해제 경로설정(root || data)\n","def get_unzip_path() :\n","    if IS_GOOGLE and UNZIP_TO_ROOT :\n","        upzip_path = '/content/'\n","    else :\n","        working_path = get_working_path()\n","        base_path    = get_base_path(working_path)\n","        upzip_path   = base_path\n","    return upzip_path\n","\n","# 압축파일 존재여부\n","def has_zipfile_in(base_path) :\n","    answer = False\n","    ext_list = ['.zip', '.rar', '.7z', '.tar', '.gz', '.bz2', '.xz', '.tar.gz', '.tar.bz2', '.tar.xz']\n","    for file_name in os.listdir(base_path) :\n","        name, ext = os.path.splitext(file_name)\n","        if ext in ext_list:\n","            answer = True\n","            break\n","    return answer\n","\n","# 압축해제 설정\n","def extract_zipfile(zipfiles,zip_path,unzip_path) :\n","    '''\n","    args : unzip_path\\n\n","    example :\\n\n","    >>> unzip_data_in(unzip_path->base_path) : data 폴더용\\n\n","    >>> unzip_data_in(unzip_path->root_path) : content 폴더용\\n\n","    '''\n","    global NEED_UNZIP\n","    if NEED_UNZIP :\n","        # 로컬 or 캐글 or 코랩루트 (3 of 1택)\n","        if  UNZIP_TO_ROOT or not IS_GOOGLE :\n","            print('압축푸는중..')\n","            for file_name in tqdm(zipfiles) :\n","                with zipfile.ZipFile(zip_path + file_name) as target_zip :\n","                    target_zip.extractall(unzip_path)\n","                    print(f'{file_name} has been successfully extracted.')\n","        # 코랩내부\n","        else :\n","            %cd {upzip_path}\n","            print('압축푸는중..')\n","            for file_name in tqdm(zipfiles) :\n","                with zipfile.ZipFile(zip_path + file_name) as target_zip :\n","                    target_zip.extractall(unzip_path)\n","                    print(f'{file_name} has been successfully extracted.')\n","            %cd {root_path}\n","\n","    # 압축해제 비활성화(여러번 압축되지않도록하기위함)\n","    else :\n","        print('message : 압축 해제가 이미 완료 되었습니다')\n","    NEED_UNZIP = False\n","\n","# 트레인데이터 경로설정\n","def get_train_path(working_path) :\n","    if UNZIP_TO_ROOT :\n","        root_path  = get_root_path()\n","        train_path = root_path + 'train/'\n","    else :\n","        base_path    = get_base_path(working_path)\n","        train_path   = base_path + 'train/'\n","    return  train_path\n","\n","# 테스트데이터 경로설정\n","def get_test_path(working_path) :\n","    if UNZIP_TO_ROOT :\n","        root_path  = get_root_path()\n","        test_path = root_path + 'test/'\n","    else :\n","        base_path    = get_base_path(working_path)\n","        test_path    = base_path + f'test'\n","    return  test_path\n","\n","\n","# 경로 구분자 컨버터설정\n","def convert_path_separator(path):\n","    # 기존경로에서 구분자 추출\n","    original_separator = os.path.sep\n","    # 로컬(Windows)인지 확인\n","    is_local = os.name == 'nt' # 'nt'는윈도우\n","    # 변경할 구분자선택\n","    new_separator = '\\\\' if is_local else '/'\n","    # 기존 구분자를 변경하고 재조립\n","    converted_path = path.replace(original_separator, new_separator)\n","\n","    return converted_path\n","\n","\n","\n","\n","\n","\n","# 시드설정\n","def set_seed(SEED):\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","\n","# Cudnn시드 결정론 설정\n","def set_deterministic():\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark     = False\n","\n","# 버전 및 코어체크\n","def print_moule_version(module_name=None) :\n","    '''\n","    info : 기본적으로 numpy,pandas,seaborn,pyplot,pytorch의\\n\n","           버전과 현재 cpu코어수를 출력합니다.\\n\n","           추가로 모듈을 인자로 입력받아 버전을 출력할수 있습니다.\\n\n","\n","    dependency : numpy , pandas, seaborn, pyplot, pytorch\\n\n","\n","    example :\n","            >>> print_moule_version(torchvision)\\n\n","            >>> --------------------------------\\n\n","            >>> selected_Ver   :  0.16.1+cpu버전\\n\n","            >>> --------------------------------\\n\n","    '''\n","    print('-'*20+'기본모듈'+'-'*20)\n","    print(f'numpy_Ver   :  {np.__version__}버전')\n","    print('-'*50)\n","    print(f'pandas_Ver  :  {pd.__version__}버전')\n","    print('-'*50)\n","    print(f'seaborn_Ver :  {sns.__version__}버전')\n","    print('-'*50)\n","    print(f'torch_Ver   :  {torch.__version__}버전')\n","    if module_name :\n","        print('-'*20+'선택한모듈'+'-'*20)\n","        print(f'selected_Ver   :  {module_name.__version__}버전')\n","    print('-'*21+'CPU코어수'+'-'*21)\n","    print(f'cpu_count   :  {os.cpu_count()}코어')\n","    print('-'*50)\n","\n","\n","# 메모리청소\n","def clean_memory():\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    # 메모리 정보 확인\n","    mem = psutil.virtual_memory()\n","\n","    # 메모리사용량 90이상일 경우 Swap메모리 클리닝(SSD,HDD등...)\n","    if mem.percent > 90:\n","        print(\"현재 사용 중인 메모리가 너무 높습니다!\\nSwap 메모리를 비웁니다\")\n","        try:\n","            psutil.swap_memory()\n","        except psutil.NoSuchProcess:\n","            print(\"해당 프로세스가 존재하지 않습니다!\")\n","\n","    print(\"메모리 청소 완료\")\n","\n","\n","# 시간계산\n","def get_elapsed_time(start_time,end_time) :\n","    elapsed_time =  end_time - start_time\n","    hours   = int(elapsed_time // 3600)\n","    minutes = int((elapsed_time % 3600) // 60)\n","    seconds = int(elapsed_time % 60)\n","    print(f' 총 소요시간 : {hours}시간 {minutes}분 {seconds}초')\n","\n","\n","# 모델별 적정 이미지사이즈 로드\n","def get_img_size_for_each_model(MODEL_NAME) :\n","    if MODEL_NAME   == 'efficientnet_b0' :\n","        img_size_h, img_size_w  = 224,224\n","    elif MODEL_NAME == 'efficientnet_b1' :\n","        img_size_h, img_size_w  = 240,240\n","    elif MODEL_NAME == 'efficientnet_b2' :\n","        img_size_h, img_size_w  = 260,260\n","    elif MODEL_NAME == 'efficientnet_b3' :\n","        img_size_h, img_size_w  = 300,300\n","    elif MODEL_NAME == 'efficientnet_b4' :\n","        img_size_h, img_size_w  = 380,380\n","    elif MODEL_NAME == 'efficientnet_b5' :\n","        img_size_h, img_size_w  = 456,456\n","    else : # 디폴트값\n","        img_size_h, img_size_w  = 256,256\n","    return img_size_h, img_size_w\n","\n","\n","\n","\n","# 데이터로더 에서 shape출력\n","def get_shape_from_dataloader(dataloader) :\n","    for batch, (img_tensor, label) in enumerate(dataloader):\n","        print('dataloder : ')\n","        print(f'\\t shape of tensor X [N,C,H,W] : {img_tensor.shape}')\n","        print(f'\\t shape of tensor y           : {label.shape}')\n","        # print(\"X->img tensor1: \", X)                                                           # X      가 3채널의 텐서정보? + 배치사이즈\n","        # print(\"X->img tensor1: \", X[0])                                                        # X[0]1개가 3채널의 텐서정보?, X[0]이 4개까지확인 가능\n","        # print(\"X->img tensor2: \", X[0][0])                                                     # X[0]3개가 2채널의 텐서정보?, X[0]이 4개까지확인 가능\n","        # print(\"X->img tensor3: \", X[0][0][0])                                                  # X[0]3개가 1채널의 텐서정보?, X[0]이 4개까지확인 가능\n","        print(\"\\t X->img tensor4: \", img_tensor[0][0][0][0])                                     # X[0]4개가 1픽셀의 스칼라값?, X[0]이 4개까지확인 가능\n","        print(\"\\t y->label      : \\n\\t\", label)                                                  # y      가 개인지 고양이인지 이진분류값의 `텐서`모음\n","        print(\"\\t y->label size   : \", len(label),'=batch_size')\n","        # print(\"y->label      : \", y[0])\n","        print()\n","        break\n","\n","\n","\n","# 작업환경 설정\n","def set_working_environ() :\n","    mount_colab()\n","    directory = Directory()\n","    root_path = directory.root_path # <- 폴더세팅 start\n","    working_path = directory.working_path\n","    base_path = directory.base_path\n","    create_working_folders(base_path)\n","    save_path = directory.save_path\n","    temp_path = directory.temp_path\n","    zip_path = directory.zip_path\n","    unzip_path = directory.unzip_path\n","    zipfiles =  ['train.zip','test.zip']\n","    extract_zipfile(zipfiles,zip_path,unzip_path)\n","\n","    print('working enviroment setting complete.')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Nt4mRi6W4WWP"},"outputs":[],"source":["#===============================================================================\n","# ▶ [파라미터] 설정모음\n","#===============================================================================\n","class Config :\n","    seed = 2023\n","    deterministic = True\n","\n","    num_workers = int(os.cpu_count())-6 if IS_LOCAL else int(os.cpu_count())\n","    batch_size = BATCH  # 최상단 설문\n","    lerning_rate = 1e-3\n","    epochs = EPOCHS     # 최상단 설문\n","    img_size_h, img_size_w = get_img_size_for_each_model(MODEL_NAME)  #디폴트값=256\n","    val_ratio = 0.1\n","    num_classes = 2\n","\n","    mean = (0.48805536, 0.45548936, 0.41698721)\n","    std  = (0.26211068, 0.25550992, 0.25817073)\n","    # mean = (0.485, 0.456, 0.406)\n","    # std  = (0.229, 0.224, 0.225)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #.cuda()가 더편함"]},{"cell_type":"markdown","metadata":{"id":"qUCNdh7gcTY3"},"source":["# 1.1 코드실행\n","-------------------------------------------"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13525,"status":"ok","timestamp":1702948691159,"user":{"displayName":"아돌퀘이사","userId":"14051741060385286083"},"user_tz":-540},"id":"fnWOcp7HKyDi","outputId":"246860d8-3450-4135-e6da-a5a467d19cf8"},"outputs":[],"source":["# 모듈설치&로드\n","install_modules()\n","import timm\n","import efficientnet_pytorch"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223,"referenced_widgets":["5ad0c153dadd4429a27305e7ed467683","eb981fece6c84559bec3f0082b411509","13931c4558f249a28c7262c9489abc82","e01f7249c1284c51bed212fd3a2b9cca","07b44212c02c4c069c93e5337d74b9c7","2b17e999f2a740c6bc6de5f912b5243e","6f913989d96446a091d1f2da9375e851","a621d84100534f478d4f41ade6b24d1a","b6b1ce81ab7b4b23905c479e2cadab6a","ab3d6371d6de481e8a85ad4c60f058b4","69630fd3d24d4c558d0b59e2c2cf40d1"]},"executionInfo":{"elapsed":34508,"status":"ok","timestamp":1702948725662,"user":{"displayName":"아돌퀘이사","userId":"14051741060385286083"},"user_tz":-540},"id":"eS4RRel8cXls","outputId":"7265e3e5-505f-44e6-e6d1-819f3f3d6416"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 환경설정 코드 자동실행\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mset_working_environ\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[7], line 302\u001b[0m, in \u001b[0;36mset_working_environ\u001b[1;34m()\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_working_environ\u001b[39m() :\n\u001b[1;32m--> 302\u001b[0m     \u001b[43mmount_colab\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m     directory \u001b[38;5;241m=\u001b[39m Directory()\n\u001b[0;32m    304\u001b[0m     root_path \u001b[38;5;241m=\u001b[39m directory\u001b[38;5;241m.\u001b[39mroot_path \u001b[38;5;66;03m# <- 폴더세팅 start\u001b[39;00m\n","Cell \u001b[1;32mIn[7], line 23\u001b[0m, in \u001b[0;36mmount_colab\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmount_colab\u001b[39m() :\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m     24\u001b[0m     drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["# 환경설정 코드 자동실행\n","set_working_environ()"]},{"cell_type":"markdown","metadata":{"id":"_rpLgkoG4WWQ"},"source":["# 2. 전처리\n","---------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sEc3oHVB4WWR"},"outputs":[],"source":["#===============================================================================\n","# ▶ [wrong 라벨링] 설정모음\n","#===============================================================================\n","noise = [\n","            'cat.3672', 'cat.4338', 'cat.5351', 'cat.5418', 'cat.7377',\n","            'cat.7564', 'cat.8456', 'cat.9171', 'cat.10029', 'cat.10712',\n","            'cat.11184', 'cat.12272',\n","            'dog.1043', 'dog.1194', 'dog.1773', 'dog.2614', 'dog.4367',\n","            'dog.5604', 'dog.6475', 'dog.8736', 'dog.9517', 'dog.10237',\n","            'dog.10747', 'dog.10801', 'dog.11299', 'dog.12376'\n","        ]\n","cat_dog = [\n","            'cat.724', 'cat.1450', 'cat.2159', 'cat.3731', 'cat.3738',\n","            'cat.3822', 'cat.4104', 'cat.4688', 'cat.5355', 'cat.5583',\n","            'cat.7194', 'cat.7920', 'cat.9444', 'cat.9882', 'cat.10181',\n","            'cat.10266', 'cat.10863', 'cat.11222', 'cat.11724',\n","            'dog.8507', 'dog.11538'\n","           ]\n","photo_unavailable = ['cat.11565', 'dog.2877', 'dog.10401', 'dog.10797']\n","\n","# 삭제하거나 label 변경이 필요한 것\n","to_delete = noise + cat_dog + photo_unavailable\n","to_cat = ['dog.4334', 'dog.11731']\n","to_dog = ['cat.4085']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6N8L-Vc54WWR"},"outputs":[],"source":["#===============================================================================\n","# ▶ [전처리함수] 설정모음\n","#===============================================================================\n","\n","# 데이터 추출\n","def get_raw_files() :\n","    directory = Directory()\n","    train_list = sorted(glob(os.path.join(directory.train_path,'*.jpg')))\n","    test_list  = sorted(glob(os.path.join(directory.test_path,'*.jpg')))\n","    print('train size / test size : ','전처리전(25000)','/', len(test_list))\n","    print('train size / test size : ', len(train_list),'/', len(test_list))\n","    return train_list, test_list\n","\n","# 개, 고양이 클래스추출(for train)\n","def get_class_category_for_train(raw_file):\n","    file_name = os.path.basename(raw_file)\n","    category, img_id, _ = file_name.split(\".\")\n","    if category == 'dog':\n","        return 1\n","    else:\n","        return 0\n","\n","\n","# 고유이미지번호(ids) 추출(for test)\n","def get_ids_for_test(raw_file) :\n","    file_name = os.path.basename(raw_file)\n","    if  IS_LOCAL :\n","        img_id=  int(file_name.split('\\\\')[-1].split('.')[0])\n","    else :\n","        img_id= int(file_name.split('/')[-1].split('.')[0])\n","    return img_id\n","\n","# 이미지 데이터 라벨링 전처리(삭제&이름변경)\n","def preprocess_image(train_path, to_delete, to_cat, to_dog):\n","    if  UNZIP_TO_ROOT:\n","        for fname in to_delete:\n","            os.remove(train_path + fname + '.jpg')\n","        for fname in to_cat:\n","            f2name = fname.replace('dog', 'cat2')\n","            os.rename(train_path + fname + '.jpg', train_path + f2name + '.jpg')\n","        for fname in to_dog:\n","            f2name = fname.replace('cat', 'dog2')\n","            os.rename(train_path + fname + '.jpg', train_path + f2name + '.jpg')\n","    else :\n","        pass\n","\n","# 이미지 메타데이터 확인\n","def get_metadata_of_image(raw_files) :\n","    raw_file = raw_files[Config.seed]\n","    img_info = Image.open(raw_file)\n","    return img_info\n","\n","# 이미지데이터 채널 가져오기\n","def get_channel_size(raw_file) :\n","    img_info = Image.open(raw_file)\n","    return 3 if img_info.mode == 'RGB' else 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0bXCYwy4WWR"},"outputs":[],"source":["#===============================================================================\n","# ▶ [증강함수] 설정모음 (!warn :This is agumentation, it'll increase total images)\n","#===============================================================================\n","# 이미지 출력\n","def show_img(raw_file) :\n","    img = cv2.imread(raw_file)\n","    plt.imshow(img)\n","\n","# 이미지 리사이즈\n","def resize_img(raw_file) :\n","    h = Config.img_size_h\n","    w = Config.img_size_w\n","    img = cv2.imread(raw_file)\n","    resize_img = cv2.resize(img, dsize=(h, w))\n","    print(resize_img)\n","    return resize_img\n","\n","# 이미지 플립\n","def flip_img(raw_file):\n","    flipped = cv2.flip(raw_file, 1)\n","    return flipped\n","\n","# 이미지 노이즈추가\n","def add_noise_img(raw_file):\n","    channel_size = get_channel_size(raw_file)\n","    h = Config.img_size_h\n","    w = Config.img_size_w\n","    noise = ( (h/6) * np.random.random((h, w,channel_size)) )\n","    raw_file = raw_file + noise\n","    raw_file[raw_file>255] = 255  # 234개만 노이즈생성\n","    return raw_file\n","\n","# 증강한 이미지출력\n","def show_agumented_img(raw_file) :\n","\n","    # 리사이즈, Flip, 노이즈 추가 이미지를 한 번에 출력\n","    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","\n","    # 이미지 리사이즈\n","    resize_version = resize_img(raw_file)\n","    # Flip 버전 생성\n","    flip_version = flip_img(resize_version)\n","    # 노이즈 추가 버전 생성\n","    noise_version = add_noise_img(resize_version)\n","\n","    # 원본 이미지\n","    axes[0].imshow(resize_version)\n","    axes[0].set_title(\"Original Image\")\n","    # Flip 이미지\n","    axes[1].imshow(flip_version)\n","    axes[1].set_title(\"Flipped Image\")\n","    # 노이즈 추가 이미지\n","    axes[2].imshow(noise_version)\n","    axes[2].set_title(\"Noised Image\")"]},{"cell_type":"markdown","metadata":{"id":"W_nvxf9I4WWR"},"source":["# 3. 데이터셋 생성\n","---------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FJ_y1Gq94WWS"},"outputs":[],"source":["#======================================================\n","# ▶ [클래스정의] 데이터셋 정의\n","#======================================================\n","\n","# 트랜스폼 클래스\n","class ImageTransform():\n","    def __init__(self, splite_mode='train'):\n","        self.split_mode = splite_mode\n","        if self.split_mode == 'train' :\n","            self.transform = \\\n","            transforms.Compose \\\n","            ([\n","                transforms.Resize((Config.img_size_h,Config.img_size_w)),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=Config.mean,std=Config.std)\n","            ])\n","        else : # val, test\n","            self.transform = \\\n","            transforms.Compose\\\n","            ([\n","                transforms.Resize((Config.img_size_h,Config.img_size_w)),\n","                # transforms.CenterCrop(Config.img_size_h,Config.img_size_w),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=Config.mean,std=Config.std)\n","            ])\n","    def __call__(self, img):\n","        return self.transform(img)\n","\n","# 데이터셋 클래스\n","class DogsVsCatsDataset(Dataset) :\n","    def __init__(self,file_list,transform) :\n","        self.file_list  = file_list\n","        self.transform  = transform\n","\n","    def __len__(self) :\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        raw_file = self.file_list[idx]\n","\n","        # 이미지텐서화\n","        img_info = Image.open(raw_file)\n","        img_tensor = self.transform(img_info)\n","\n","        # 이미지라벨링\n","        if self.transform.split_mode == 'test' :\n","            ids = get_ids_for_test(raw_file)\n","            return img_tensor, ids\n","        else :\n","            label = get_class_category_for_train(raw_file)\n","            return img_tensor, label\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2375,"status":"ok","timestamp":1702948728026,"user":{"displayName":"아돌퀘이사","userId":"14051741060385286083"},"user_tz":-540},"id":"pJDf8n9d5Vok","outputId":"c82738e7-1f08-442f-8794-804d9e0c75dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/프로젝트/[CV]개&고양이 분류/\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","train size / test size :  전처리전(25000) / 12500\n","train size / test size :  25000 / 12500\n"]}],"source":["#======================================================\n","# ▶ Dataset & Loader 객체생성 (트/테/발 설정)\n","#======================================================\n","train_list, test_list = get_raw_files()\n","# preprocess_image(directory.train_path, to_delete, to_cat, to_dog)\n","train_list, val_list  = train_test_split(train_list, test_size = Config.val_ratio, random_state=Config.seed, shuffle=True)\n","\n","train_dataset = DogsVsCatsDataset(train_list,ImageTransform(splite_mode='train'))\n","val_dataset   = DogsVsCatsDataset(val_list,ImageTransform(splite_mode='val'))\n","test_dataset  = DogsVsCatsDataset(test_list,ImageTransform(splite_mode='test'))\n","\n","train_loader = DataLoader(train_dataset,Config.batch_size,shuffle=True)\n","val_loader   = DataLoader(val_dataset,Config.batch_size,shuffle=False)\n","test_loader  = DataLoader(test_dataset,Config.batch_size,shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":615,"status":"ok","timestamp":1702948728637,"user":{"displayName":"아돌퀘이사","userId":"14051741060385286083"},"user_tz":-540},"id":"A39IfzLh4WWS","outputId":"2b8053a3-fbfb-42b1-c38d-a4bf90e6fb65"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataloder : \n","\t shape of tensor X [N,C,H,W] : torch.Size([32, 3, 456, 456])\n","\t shape of tensor y           : torch.Size([32])\n","\t X->img tensor4:  tensor(1.5642)\n","\t y->label      : \n","\t tensor([0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n","        1, 1, 1, 0, 0, 1, 1, 1])\n","\t y->label size   :  32 =batch_size\n","\n"]}],"source":["# 훈련 데이터로더 shape 체크\n","get_shape_from_dataloader(train_loader)"]},{"cell_type":"markdown","metadata":{"id":"TfnyP6cT4WWT"},"source":["# 4. 전이학습(with 커스텀튜닝)\n","--------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"akWWK9x44WWT"},"outputs":[],"source":["#===============================================================================\n","# ▶ [모델링함수] 설정모음\n","#===============================================================================\n","\n","# 전이학습 모델 로드\n","def get_transfer_model(MODEL_NAME,num_classes, model_dict=None):\n","    # 사전에서 모델을 로드\n","    if  MODEL_NAME in model_dict:\n","        return model_dict[MODEL_NAME]\n","\n","    # torchvision에서 모델을 로드\n","    elif hasattr(models, MODEL_NAME):\n","        return getattr(models, MODEL_NAME)(pretrained=True)\n","\n","    # timm에서 모델을 로드.\n","    try:\n","        return timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes)\n","    except ValueError:\n","        pass\n","\n","    # 어떤 방법으로도 모델을 가져오지 못했을 경우 예외발생\n","    raise ModelNotFoundError\n","\n","# 모델 프리셋\n","def get_model_dict(num_classes) :\n","    model_dict =\\\n","    {\n","        'efficientnet_b0': timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes),\n","        'efficientnet_b1': timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes),\n","        'efficientnet_b2': timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes),\n","        'efficientnet_b3': timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes),\n","        'efficientnet_b4': timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes),\n","        'efficientnet_b5': timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes),\n","        'resnet50'       : models.resnet50,\n","    }\n","    return model_dict\n","\n","# 프리징(분류문제용:EfficientNet)\n","def freeze_pretrained_model_for_classifier(model,model_dict,MODEL_NAME='efficientnet_b1'):\n","    \"\"\"\n","    Info : 사전 훈련된 모델의 파라미터를 프리징 합니다.\\n\n","           classifier 레이어만 훈련하고 나머지 레이어는 훈련하지 않습니다.\\n\n","           모델명이 arguments에 없을경우 디폴트값으로\\n\n","           `efficientnet_b1`이 설정됩니다.\\n\n","\n","    Args:\n","        model: Pre-trained model, \\n\n","        model_dict : model dictionary preset\\n\n","        MODEL_NAME : source model name\n","\n","    Returns:\n","        params_to_freeze   : 훈련하지 않을 파라미터 리스트\n","        params_to_optimizer: 훈련할 파라미터 리스트\n","    \"\"\"\n","    # 인자로들어온 모델명이 있는지 모델 딕셔너리와 비교후, final layer식별자 지정\n","    if any(keyword in MODEL_NAME for keyword in model_dict):\n","        final_layer = \"classifier\"\n","    else:\n","        final_layer = None  # 모델추가예정 e.g. _fc, head, ...\n","\n","    # classifier층 이름 얻기(일반적으로 분류문제인경우 마지막 계층 식별)\n","    classifier_names = [name for name, _ in model.named_parameters() if final_layer in name]\n","\n","    # 동결할 파라미터 리스트생성\n","    params_to_freeze = [param for name, param in model.named_parameters() if name not in classifier_names]\n","\n","    # 훈련할 파라미터 리스트생성\n","    params_to_optimizer = [param for name, param in model.named_parameters() if name in classifier_names]\n","\n","    # 훈련하지 않을 파라미터를 프리징\n","    for param in params_to_freeze:\n","      param.requires_grad = False\n","    # 훈련시킬 파라미터는 optimizer로 보냄\n","    for param in params_to_optimizer :\n","      param.requires_grad = True\n","\n","    return params_to_freeze, params_to_optimizer\n","\n","\n","# 커스텀분류층 추가(옵션)\n","def add_custom_classifier(model) :\n","    # 모델 파라미터 커스터마이징\n","    num_features = model.classifier[1].in_features\n","    model.classifier = nn.Sequential()\n","\n","    # 커스텀분류층 추가\n","    custom_classifier = nn.Sequential(\n","                                        nn.Linear(int(num_features), 512),\n","                                        nn.ReLU(),\n","\n","                                        nn.Linear(512, 2),\n","                                        nn.Sigmoid() # or Softmax()\n","                                    )\n","    # 새로운층을 적용\n","    model.classifier = custom_classifier\n","\n","\n","# 파라미터 플로우 브리핑\n","def show_summary_of_params(model) :\n","    train_list,test_list = get_raw_files()\n","    channel_size = get_channel_size(train_list[Config.seed])\n","    summary(model,(channel_size,Config.img_size_h,Config.img_size_w))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f35833bcb4694ed8815ee2a912f0a3bc","158afc3e0d294243beb0d36c9b17a7ba","bf7e5d96574d4b8780f59f6ad3e1687e","73d7ec68e9f9472ea8a54aff94930ee7","c1a476fd6a8d4a46a37513bcf5b24a5a","a0b75188a3ee40418909db07c7a1c984","6195a244e9e542649851589f5e67c257","86618ec5cc5e451895accb483465d9ca","75247329b999457da599d1c499ba33bf","1379683ee94645f688711fea278d8978","ef62ef33cde44c02bb88c1ae08c6ddf5"]},"executionInfo":{"elapsed":8417,"status":"ok","timestamp":1702948737053,"user":{"displayName":"아돌퀘이사","userId":"14051741060385286083"},"user_tz":-540},"id":"c_qigQcs4WWT","outputId":"ad8f314c-fbee-4f26-f74a-7c9b17ce8de9"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f35833bcb4694ed8815ee2a912f0a3bc","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/122M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/프로젝트/[CV]개&고양이 분류/\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","train size / test size :  전처리전(25000) / 12500\n","train size / test size :  25000 / 12500\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 48, 228, 228]           1,296\n","          Identity-2         [-1, 48, 228, 228]               0\n","              SiLU-3         [-1, 48, 228, 228]               0\n","    BatchNormAct2d-4         [-1, 48, 228, 228]              96\n","            Conv2d-5         [-1, 48, 228, 228]             432\n","          Identity-6         [-1, 48, 228, 228]               0\n","              SiLU-7         [-1, 48, 228, 228]               0\n","    BatchNormAct2d-8         [-1, 48, 228, 228]              96\n","            Conv2d-9             [-1, 12, 1, 1]             588\n","             SiLU-10             [-1, 12, 1, 1]               0\n","           Conv2d-11             [-1, 48, 1, 1]             624\n","          Sigmoid-12             [-1, 48, 1, 1]               0\n","    SqueezeExcite-13         [-1, 48, 228, 228]               0\n","           Conv2d-14         [-1, 24, 228, 228]           1,152\n","         Identity-15         [-1, 24, 228, 228]               0\n","         Identity-16         [-1, 24, 228, 228]               0\n","   BatchNormAct2d-17         [-1, 24, 228, 228]              48\n","DepthwiseSeparableConv-18         [-1, 24, 228, 228]               0\n","           Conv2d-19         [-1, 24, 228, 228]             216\n","         Identity-20         [-1, 24, 228, 228]               0\n","             SiLU-21         [-1, 24, 228, 228]               0\n","   BatchNormAct2d-22         [-1, 24, 228, 228]              48\n","           Conv2d-23              [-1, 6, 1, 1]             150\n","             SiLU-24              [-1, 6, 1, 1]               0\n","           Conv2d-25             [-1, 24, 1, 1]             168\n","          Sigmoid-26             [-1, 24, 1, 1]               0\n","    SqueezeExcite-27         [-1, 24, 228, 228]               0\n","           Conv2d-28         [-1, 24, 228, 228]             576\n","         Identity-29         [-1, 24, 228, 228]               0\n","         Identity-30         [-1, 24, 228, 228]               0\n","   BatchNormAct2d-31         [-1, 24, 228, 228]              48\n","         Identity-32         [-1, 24, 228, 228]               0\n","DepthwiseSeparableConv-33         [-1, 24, 228, 228]               0\n","           Conv2d-34         [-1, 24, 228, 228]             216\n","         Identity-35         [-1, 24, 228, 228]               0\n","             SiLU-36         [-1, 24, 228, 228]               0\n","   BatchNormAct2d-37         [-1, 24, 228, 228]              48\n","           Conv2d-38              [-1, 6, 1, 1]             150\n","             SiLU-39              [-1, 6, 1, 1]               0\n","           Conv2d-40             [-1, 24, 1, 1]             168\n","          Sigmoid-41             [-1, 24, 1, 1]               0\n","    SqueezeExcite-42         [-1, 24, 228, 228]               0\n","           Conv2d-43         [-1, 24, 228, 228]             576\n","         Identity-44         [-1, 24, 228, 228]               0\n","         Identity-45         [-1, 24, 228, 228]               0\n","   BatchNormAct2d-46         [-1, 24, 228, 228]              48\n","         Identity-47         [-1, 24, 228, 228]               0\n","DepthwiseSeparableConv-48         [-1, 24, 228, 228]               0\n","           Conv2d-49        [-1, 144, 228, 228]           3,456\n","         Identity-50        [-1, 144, 228, 228]               0\n","             SiLU-51        [-1, 144, 228, 228]               0\n","   BatchNormAct2d-52        [-1, 144, 228, 228]             288\n","           Conv2d-53        [-1, 144, 114, 114]           1,296\n","         Identity-54        [-1, 144, 114, 114]               0\n","             SiLU-55        [-1, 144, 114, 114]               0\n","   BatchNormAct2d-56        [-1, 144, 114, 114]             288\n","           Conv2d-57              [-1, 6, 1, 1]             870\n","             SiLU-58              [-1, 6, 1, 1]               0\n","           Conv2d-59            [-1, 144, 1, 1]           1,008\n","          Sigmoid-60            [-1, 144, 1, 1]               0\n","    SqueezeExcite-61        [-1, 144, 114, 114]               0\n","           Conv2d-62         [-1, 40, 114, 114]           5,760\n","         Identity-63         [-1, 40, 114, 114]               0\n","         Identity-64         [-1, 40, 114, 114]               0\n","   BatchNormAct2d-65         [-1, 40, 114, 114]              80\n"," InvertedResidual-66         [-1, 40, 114, 114]               0\n","           Conv2d-67        [-1, 240, 114, 114]           9,600\n","         Identity-68        [-1, 240, 114, 114]               0\n","             SiLU-69        [-1, 240, 114, 114]               0\n","   BatchNormAct2d-70        [-1, 240, 114, 114]             480\n","           Conv2d-71        [-1, 240, 114, 114]           2,160\n","         Identity-72        [-1, 240, 114, 114]               0\n","             SiLU-73        [-1, 240, 114, 114]               0\n","   BatchNormAct2d-74        [-1, 240, 114, 114]             480\n","           Conv2d-75             [-1, 10, 1, 1]           2,410\n","             SiLU-76             [-1, 10, 1, 1]               0\n","           Conv2d-77            [-1, 240, 1, 1]           2,640\n","          Sigmoid-78            [-1, 240, 1, 1]               0\n","    SqueezeExcite-79        [-1, 240, 114, 114]               0\n","           Conv2d-80         [-1, 40, 114, 114]           9,600\n","         Identity-81         [-1, 40, 114, 114]               0\n","         Identity-82         [-1, 40, 114, 114]               0\n","   BatchNormAct2d-83         [-1, 40, 114, 114]              80\n","         Identity-84         [-1, 40, 114, 114]               0\n"," InvertedResidual-85         [-1, 40, 114, 114]               0\n","           Conv2d-86        [-1, 240, 114, 114]           9,600\n","         Identity-87        [-1, 240, 114, 114]               0\n","             SiLU-88        [-1, 240, 114, 114]               0\n","   BatchNormAct2d-89        [-1, 240, 114, 114]             480\n","           Conv2d-90        [-1, 240, 114, 114]           2,160\n","         Identity-91        [-1, 240, 114, 114]               0\n","             SiLU-92        [-1, 240, 114, 114]               0\n","   BatchNormAct2d-93        [-1, 240, 114, 114]             480\n","           Conv2d-94             [-1, 10, 1, 1]           2,410\n","             SiLU-95             [-1, 10, 1, 1]               0\n","           Conv2d-96            [-1, 240, 1, 1]           2,640\n","          Sigmoid-97            [-1, 240, 1, 1]               0\n","    SqueezeExcite-98        [-1, 240, 114, 114]               0\n","           Conv2d-99         [-1, 40, 114, 114]           9,600\n","        Identity-100         [-1, 40, 114, 114]               0\n","        Identity-101         [-1, 40, 114, 114]               0\n","  BatchNormAct2d-102         [-1, 40, 114, 114]              80\n","        Identity-103         [-1, 40, 114, 114]               0\n","InvertedResidual-104         [-1, 40, 114, 114]               0\n","          Conv2d-105        [-1, 240, 114, 114]           9,600\n","        Identity-106        [-1, 240, 114, 114]               0\n","            SiLU-107        [-1, 240, 114, 114]               0\n","  BatchNormAct2d-108        [-1, 240, 114, 114]             480\n","          Conv2d-109        [-1, 240, 114, 114]           2,160\n","        Identity-110        [-1, 240, 114, 114]               0\n","            SiLU-111        [-1, 240, 114, 114]               0\n","  BatchNormAct2d-112        [-1, 240, 114, 114]             480\n","          Conv2d-113             [-1, 10, 1, 1]           2,410\n","            SiLU-114             [-1, 10, 1, 1]               0\n","          Conv2d-115            [-1, 240, 1, 1]           2,640\n","         Sigmoid-116            [-1, 240, 1, 1]               0\n","   SqueezeExcite-117        [-1, 240, 114, 114]               0\n","          Conv2d-118         [-1, 40, 114, 114]           9,600\n","        Identity-119         [-1, 40, 114, 114]               0\n","        Identity-120         [-1, 40, 114, 114]               0\n","  BatchNormAct2d-121         [-1, 40, 114, 114]              80\n","        Identity-122         [-1, 40, 114, 114]               0\n","InvertedResidual-123         [-1, 40, 114, 114]               0\n","          Conv2d-124        [-1, 240, 114, 114]           9,600\n","        Identity-125        [-1, 240, 114, 114]               0\n","            SiLU-126        [-1, 240, 114, 114]               0\n","  BatchNormAct2d-127        [-1, 240, 114, 114]             480\n","          Conv2d-128        [-1, 240, 114, 114]           2,160\n","        Identity-129        [-1, 240, 114, 114]               0\n","            SiLU-130        [-1, 240, 114, 114]               0\n","  BatchNormAct2d-131        [-1, 240, 114, 114]             480\n","          Conv2d-132             [-1, 10, 1, 1]           2,410\n","            SiLU-133             [-1, 10, 1, 1]               0\n","          Conv2d-134            [-1, 240, 1, 1]           2,640\n","         Sigmoid-135            [-1, 240, 1, 1]               0\n","   SqueezeExcite-136        [-1, 240, 114, 114]               0\n","          Conv2d-137         [-1, 40, 114, 114]           9,600\n","        Identity-138         [-1, 40, 114, 114]               0\n","        Identity-139         [-1, 40, 114, 114]               0\n","  BatchNormAct2d-140         [-1, 40, 114, 114]              80\n","        Identity-141         [-1, 40, 114, 114]               0\n","InvertedResidual-142         [-1, 40, 114, 114]               0\n","          Conv2d-143        [-1, 240, 114, 114]           9,600\n","        Identity-144        [-1, 240, 114, 114]               0\n","            SiLU-145        [-1, 240, 114, 114]               0\n","  BatchNormAct2d-146        [-1, 240, 114, 114]             480\n","          Conv2d-147          [-1, 240, 57, 57]           6,000\n","        Identity-148          [-1, 240, 57, 57]               0\n","            SiLU-149          [-1, 240, 57, 57]               0\n","  BatchNormAct2d-150          [-1, 240, 57, 57]             480\n","          Conv2d-151             [-1, 10, 1, 1]           2,410\n","            SiLU-152             [-1, 10, 1, 1]               0\n","          Conv2d-153            [-1, 240, 1, 1]           2,640\n","         Sigmoid-154            [-1, 240, 1, 1]               0\n","   SqueezeExcite-155          [-1, 240, 57, 57]               0\n","          Conv2d-156           [-1, 64, 57, 57]          15,360\n","        Identity-157           [-1, 64, 57, 57]               0\n","        Identity-158           [-1, 64, 57, 57]               0\n","  BatchNormAct2d-159           [-1, 64, 57, 57]             128\n","InvertedResidual-160           [-1, 64, 57, 57]               0\n","          Conv2d-161          [-1, 384, 57, 57]          24,576\n","        Identity-162          [-1, 384, 57, 57]               0\n","            SiLU-163          [-1, 384, 57, 57]               0\n","  BatchNormAct2d-164          [-1, 384, 57, 57]             768\n","          Conv2d-165          [-1, 384, 57, 57]           9,600\n","        Identity-166          [-1, 384, 57, 57]               0\n","            SiLU-167          [-1, 384, 57, 57]               0\n","  BatchNormAct2d-168          [-1, 384, 57, 57]             768\n","          Conv2d-169             [-1, 16, 1, 1]           6,160\n","            SiLU-170             [-1, 16, 1, 1]               0\n","          Conv2d-171            [-1, 384, 1, 1]           6,528\n","         Sigmoid-172            [-1, 384, 1, 1]               0\n","   SqueezeExcite-173          [-1, 384, 57, 57]               0\n","          Conv2d-174           [-1, 64, 57, 57]          24,576\n","        Identity-175           [-1, 64, 57, 57]               0\n","        Identity-176           [-1, 64, 57, 57]               0\n","  BatchNormAct2d-177           [-1, 64, 57, 57]             128\n","        Identity-178           [-1, 64, 57, 57]               0\n","InvertedResidual-179           [-1, 64, 57, 57]               0\n","          Conv2d-180          [-1, 384, 57, 57]          24,576\n","        Identity-181          [-1, 384, 57, 57]               0\n","            SiLU-182          [-1, 384, 57, 57]               0\n","  BatchNormAct2d-183          [-1, 384, 57, 57]             768\n","          Conv2d-184          [-1, 384, 57, 57]           9,600\n","        Identity-185          [-1, 384, 57, 57]               0\n","            SiLU-186          [-1, 384, 57, 57]               0\n","  BatchNormAct2d-187          [-1, 384, 57, 57]             768\n","          Conv2d-188             [-1, 16, 1, 1]           6,160\n","            SiLU-189             [-1, 16, 1, 1]               0\n","          Conv2d-190            [-1, 384, 1, 1]           6,528\n","         Sigmoid-191            [-1, 384, 1, 1]               0\n","   SqueezeExcite-192          [-1, 384, 57, 57]               0\n","          Conv2d-193           [-1, 64, 57, 57]          24,576\n","        Identity-194           [-1, 64, 57, 57]               0\n","        Identity-195           [-1, 64, 57, 57]               0\n","  BatchNormAct2d-196           [-1, 64, 57, 57]             128\n","        Identity-197           [-1, 64, 57, 57]               0\n","InvertedResidual-198           [-1, 64, 57, 57]               0\n","          Conv2d-199          [-1, 384, 57, 57]          24,576\n","        Identity-200          [-1, 384, 57, 57]               0\n","            SiLU-201          [-1, 384, 57, 57]               0\n","  BatchNormAct2d-202          [-1, 384, 57, 57]             768\n","          Conv2d-203          [-1, 384, 57, 57]           9,600\n","        Identity-204          [-1, 384, 57, 57]               0\n","            SiLU-205          [-1, 384, 57, 57]               0\n","  BatchNormAct2d-206          [-1, 384, 57, 57]             768\n","          Conv2d-207             [-1, 16, 1, 1]           6,160\n","            SiLU-208             [-1, 16, 1, 1]               0\n","          Conv2d-209            [-1, 384, 1, 1]           6,528\n","         Sigmoid-210            [-1, 384, 1, 1]               0\n","   SqueezeExcite-211          [-1, 384, 57, 57]               0\n","          Conv2d-212           [-1, 64, 57, 57]          24,576\n","        Identity-213           [-1, 64, 57, 57]               0\n","        Identity-214           [-1, 64, 57, 57]               0\n","  BatchNormAct2d-215           [-1, 64, 57, 57]             128\n","        Identity-216           [-1, 64, 57, 57]               0\n","InvertedResidual-217           [-1, 64, 57, 57]               0\n","          Conv2d-218          [-1, 384, 57, 57]          24,576\n","        Identity-219          [-1, 384, 57, 57]               0\n","            SiLU-220          [-1, 384, 57, 57]               0\n","  BatchNormAct2d-221          [-1, 384, 57, 57]             768\n","          Conv2d-222          [-1, 384, 57, 57]           9,600\n","        Identity-223          [-1, 384, 57, 57]               0\n","            SiLU-224          [-1, 384, 57, 57]               0\n","  BatchNormAct2d-225          [-1, 384, 57, 57]             768\n","          Conv2d-226             [-1, 16, 1, 1]           6,160\n","            SiLU-227             [-1, 16, 1, 1]               0\n","          Conv2d-228            [-1, 384, 1, 1]           6,528\n","         Sigmoid-229            [-1, 384, 1, 1]               0\n","   SqueezeExcite-230          [-1, 384, 57, 57]               0\n","          Conv2d-231           [-1, 64, 57, 57]          24,576\n","        Identity-232           [-1, 64, 57, 57]               0\n","        Identity-233           [-1, 64, 57, 57]               0\n","  BatchNormAct2d-234           [-1, 64, 57, 57]             128\n","        Identity-235           [-1, 64, 57, 57]               0\n","InvertedResidual-236           [-1, 64, 57, 57]               0\n","          Conv2d-237          [-1, 384, 57, 57]          24,576\n","        Identity-238          [-1, 384, 57, 57]               0\n","            SiLU-239          [-1, 384, 57, 57]               0\n","  BatchNormAct2d-240          [-1, 384, 57, 57]             768\n","          Conv2d-241          [-1, 384, 29, 29]           3,456\n","        Identity-242          [-1, 384, 29, 29]               0\n","            SiLU-243          [-1, 384, 29, 29]               0\n","  BatchNormAct2d-244          [-1, 384, 29, 29]             768\n","          Conv2d-245             [-1, 16, 1, 1]           6,160\n","            SiLU-246             [-1, 16, 1, 1]               0\n","          Conv2d-247            [-1, 384, 1, 1]           6,528\n","         Sigmoid-248            [-1, 384, 1, 1]               0\n","   SqueezeExcite-249          [-1, 384, 29, 29]               0\n","          Conv2d-250          [-1, 128, 29, 29]          49,152\n","        Identity-251          [-1, 128, 29, 29]               0\n","        Identity-252          [-1, 128, 29, 29]               0\n","  BatchNormAct2d-253          [-1, 128, 29, 29]             256\n","InvertedResidual-254          [-1, 128, 29, 29]               0\n","          Conv2d-255          [-1, 768, 29, 29]          98,304\n","        Identity-256          [-1, 768, 29, 29]               0\n","            SiLU-257          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-258          [-1, 768, 29, 29]           1,536\n","          Conv2d-259          [-1, 768, 29, 29]           6,912\n","        Identity-260          [-1, 768, 29, 29]               0\n","            SiLU-261          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-262          [-1, 768, 29, 29]           1,536\n","          Conv2d-263             [-1, 32, 1, 1]          24,608\n","            SiLU-264             [-1, 32, 1, 1]               0\n","          Conv2d-265            [-1, 768, 1, 1]          25,344\n","         Sigmoid-266            [-1, 768, 1, 1]               0\n","   SqueezeExcite-267          [-1, 768, 29, 29]               0\n","          Conv2d-268          [-1, 128, 29, 29]          98,304\n","        Identity-269          [-1, 128, 29, 29]               0\n","        Identity-270          [-1, 128, 29, 29]               0\n","  BatchNormAct2d-271          [-1, 128, 29, 29]             256\n","        Identity-272          [-1, 128, 29, 29]               0\n","InvertedResidual-273          [-1, 128, 29, 29]               0\n","          Conv2d-274          [-1, 768, 29, 29]          98,304\n","        Identity-275          [-1, 768, 29, 29]               0\n","            SiLU-276          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-277          [-1, 768, 29, 29]           1,536\n","          Conv2d-278          [-1, 768, 29, 29]           6,912\n","        Identity-279          [-1, 768, 29, 29]               0\n","            SiLU-280          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-281          [-1, 768, 29, 29]           1,536\n","          Conv2d-282             [-1, 32, 1, 1]          24,608\n","            SiLU-283             [-1, 32, 1, 1]               0\n","          Conv2d-284            [-1, 768, 1, 1]          25,344\n","         Sigmoid-285            [-1, 768, 1, 1]               0\n","   SqueezeExcite-286          [-1, 768, 29, 29]               0\n","          Conv2d-287          [-1, 128, 29, 29]          98,304\n","        Identity-288          [-1, 128, 29, 29]               0\n","        Identity-289          [-1, 128, 29, 29]               0\n","  BatchNormAct2d-290          [-1, 128, 29, 29]             256\n","        Identity-291          [-1, 128, 29, 29]               0\n","InvertedResidual-292          [-1, 128, 29, 29]               0\n","          Conv2d-293          [-1, 768, 29, 29]          98,304\n","        Identity-294          [-1, 768, 29, 29]               0\n","            SiLU-295          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-296          [-1, 768, 29, 29]           1,536\n","          Conv2d-297          [-1, 768, 29, 29]           6,912\n","        Identity-298          [-1, 768, 29, 29]               0\n","            SiLU-299          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-300          [-1, 768, 29, 29]           1,536\n","          Conv2d-301             [-1, 32, 1, 1]          24,608\n","            SiLU-302             [-1, 32, 1, 1]               0\n","          Conv2d-303            [-1, 768, 1, 1]          25,344\n","         Sigmoid-304            [-1, 768, 1, 1]               0\n","   SqueezeExcite-305          [-1, 768, 29, 29]               0\n","          Conv2d-306          [-1, 128, 29, 29]          98,304\n","        Identity-307          [-1, 128, 29, 29]               0\n","        Identity-308          [-1, 128, 29, 29]               0\n","  BatchNormAct2d-309          [-1, 128, 29, 29]             256\n","        Identity-310          [-1, 128, 29, 29]               0\n","InvertedResidual-311          [-1, 128, 29, 29]               0\n","          Conv2d-312          [-1, 768, 29, 29]          98,304\n","        Identity-313          [-1, 768, 29, 29]               0\n","            SiLU-314          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-315          [-1, 768, 29, 29]           1,536\n","          Conv2d-316          [-1, 768, 29, 29]           6,912\n","        Identity-317          [-1, 768, 29, 29]               0\n","            SiLU-318          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-319          [-1, 768, 29, 29]           1,536\n","          Conv2d-320             [-1, 32, 1, 1]          24,608\n","            SiLU-321             [-1, 32, 1, 1]               0\n","          Conv2d-322            [-1, 768, 1, 1]          25,344\n","         Sigmoid-323            [-1, 768, 1, 1]               0\n","   SqueezeExcite-324          [-1, 768, 29, 29]               0\n","          Conv2d-325          [-1, 128, 29, 29]          98,304\n","        Identity-326          [-1, 128, 29, 29]               0\n","        Identity-327          [-1, 128, 29, 29]               0\n","  BatchNormAct2d-328          [-1, 128, 29, 29]             256\n","        Identity-329          [-1, 128, 29, 29]               0\n","InvertedResidual-330          [-1, 128, 29, 29]               0\n","          Conv2d-331          [-1, 768, 29, 29]          98,304\n","        Identity-332          [-1, 768, 29, 29]               0\n","            SiLU-333          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-334          [-1, 768, 29, 29]           1,536\n","          Conv2d-335          [-1, 768, 29, 29]           6,912\n","        Identity-336          [-1, 768, 29, 29]               0\n","            SiLU-337          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-338          [-1, 768, 29, 29]           1,536\n","          Conv2d-339             [-1, 32, 1, 1]          24,608\n","            SiLU-340             [-1, 32, 1, 1]               0\n","          Conv2d-341            [-1, 768, 1, 1]          25,344\n","         Sigmoid-342            [-1, 768, 1, 1]               0\n","   SqueezeExcite-343          [-1, 768, 29, 29]               0\n","          Conv2d-344          [-1, 128, 29, 29]          98,304\n","        Identity-345          [-1, 128, 29, 29]               0\n","        Identity-346          [-1, 128, 29, 29]               0\n","  BatchNormAct2d-347          [-1, 128, 29, 29]             256\n","        Identity-348          [-1, 128, 29, 29]               0\n","InvertedResidual-349          [-1, 128, 29, 29]               0\n","          Conv2d-350          [-1, 768, 29, 29]          98,304\n","        Identity-351          [-1, 768, 29, 29]               0\n","            SiLU-352          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-353          [-1, 768, 29, 29]           1,536\n","          Conv2d-354          [-1, 768, 29, 29]           6,912\n","        Identity-355          [-1, 768, 29, 29]               0\n","            SiLU-356          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-357          [-1, 768, 29, 29]           1,536\n","          Conv2d-358             [-1, 32, 1, 1]          24,608\n","            SiLU-359             [-1, 32, 1, 1]               0\n","          Conv2d-360            [-1, 768, 1, 1]          25,344\n","         Sigmoid-361            [-1, 768, 1, 1]               0\n","   SqueezeExcite-362          [-1, 768, 29, 29]               0\n","          Conv2d-363          [-1, 128, 29, 29]          98,304\n","        Identity-364          [-1, 128, 29, 29]               0\n","        Identity-365          [-1, 128, 29, 29]               0\n","  BatchNormAct2d-366          [-1, 128, 29, 29]             256\n","        Identity-367          [-1, 128, 29, 29]               0\n","InvertedResidual-368          [-1, 128, 29, 29]               0\n","          Conv2d-369          [-1, 768, 29, 29]          98,304\n","        Identity-370          [-1, 768, 29, 29]               0\n","            SiLU-371          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-372          [-1, 768, 29, 29]           1,536\n","          Conv2d-373          [-1, 768, 29, 29]          19,200\n","        Identity-374          [-1, 768, 29, 29]               0\n","            SiLU-375          [-1, 768, 29, 29]               0\n","  BatchNormAct2d-376          [-1, 768, 29, 29]           1,536\n","          Conv2d-377             [-1, 32, 1, 1]          24,608\n","            SiLU-378             [-1, 32, 1, 1]               0\n","          Conv2d-379            [-1, 768, 1, 1]          25,344\n","         Sigmoid-380            [-1, 768, 1, 1]               0\n","   SqueezeExcite-381          [-1, 768, 29, 29]               0\n","          Conv2d-382          [-1, 176, 29, 29]         135,168\n","        Identity-383          [-1, 176, 29, 29]               0\n","        Identity-384          [-1, 176, 29, 29]               0\n","  BatchNormAct2d-385          [-1, 176, 29, 29]             352\n","InvertedResidual-386          [-1, 176, 29, 29]               0\n","          Conv2d-387         [-1, 1056, 29, 29]         185,856\n","        Identity-388         [-1, 1056, 29, 29]               0\n","            SiLU-389         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-390         [-1, 1056, 29, 29]           2,112\n","          Conv2d-391         [-1, 1056, 29, 29]          26,400\n","        Identity-392         [-1, 1056, 29, 29]               0\n","            SiLU-393         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-394         [-1, 1056, 29, 29]           2,112\n","          Conv2d-395             [-1, 44, 1, 1]          46,508\n","            SiLU-396             [-1, 44, 1, 1]               0\n","          Conv2d-397           [-1, 1056, 1, 1]          47,520\n","         Sigmoid-398           [-1, 1056, 1, 1]               0\n","   SqueezeExcite-399         [-1, 1056, 29, 29]               0\n","          Conv2d-400          [-1, 176, 29, 29]         185,856\n","        Identity-401          [-1, 176, 29, 29]               0\n","        Identity-402          [-1, 176, 29, 29]               0\n","  BatchNormAct2d-403          [-1, 176, 29, 29]             352\n","        Identity-404          [-1, 176, 29, 29]               0\n","InvertedResidual-405          [-1, 176, 29, 29]               0\n","          Conv2d-406         [-1, 1056, 29, 29]         185,856\n","        Identity-407         [-1, 1056, 29, 29]               0\n","            SiLU-408         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-409         [-1, 1056, 29, 29]           2,112\n","          Conv2d-410         [-1, 1056, 29, 29]          26,400\n","        Identity-411         [-1, 1056, 29, 29]               0\n","            SiLU-412         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-413         [-1, 1056, 29, 29]           2,112\n","          Conv2d-414             [-1, 44, 1, 1]          46,508\n","            SiLU-415             [-1, 44, 1, 1]               0\n","          Conv2d-416           [-1, 1056, 1, 1]          47,520\n","         Sigmoid-417           [-1, 1056, 1, 1]               0\n","   SqueezeExcite-418         [-1, 1056, 29, 29]               0\n","          Conv2d-419          [-1, 176, 29, 29]         185,856\n","        Identity-420          [-1, 176, 29, 29]               0\n","        Identity-421          [-1, 176, 29, 29]               0\n","  BatchNormAct2d-422          [-1, 176, 29, 29]             352\n","        Identity-423          [-1, 176, 29, 29]               0\n","InvertedResidual-424          [-1, 176, 29, 29]               0\n","          Conv2d-425         [-1, 1056, 29, 29]         185,856\n","        Identity-426         [-1, 1056, 29, 29]               0\n","            SiLU-427         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-428         [-1, 1056, 29, 29]           2,112\n","          Conv2d-429         [-1, 1056, 29, 29]          26,400\n","        Identity-430         [-1, 1056, 29, 29]               0\n","            SiLU-431         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-432         [-1, 1056, 29, 29]           2,112\n","          Conv2d-433             [-1, 44, 1, 1]          46,508\n","            SiLU-434             [-1, 44, 1, 1]               0\n","          Conv2d-435           [-1, 1056, 1, 1]          47,520\n","         Sigmoid-436           [-1, 1056, 1, 1]               0\n","   SqueezeExcite-437         [-1, 1056, 29, 29]               0\n","          Conv2d-438          [-1, 176, 29, 29]         185,856\n","        Identity-439          [-1, 176, 29, 29]               0\n","        Identity-440          [-1, 176, 29, 29]               0\n","  BatchNormAct2d-441          [-1, 176, 29, 29]             352\n","        Identity-442          [-1, 176, 29, 29]               0\n","InvertedResidual-443          [-1, 176, 29, 29]               0\n","          Conv2d-444         [-1, 1056, 29, 29]         185,856\n","        Identity-445         [-1, 1056, 29, 29]               0\n","            SiLU-446         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-447         [-1, 1056, 29, 29]           2,112\n","          Conv2d-448         [-1, 1056, 29, 29]          26,400\n","        Identity-449         [-1, 1056, 29, 29]               0\n","            SiLU-450         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-451         [-1, 1056, 29, 29]           2,112\n","          Conv2d-452             [-1, 44, 1, 1]          46,508\n","            SiLU-453             [-1, 44, 1, 1]               0\n","          Conv2d-454           [-1, 1056, 1, 1]          47,520\n","         Sigmoid-455           [-1, 1056, 1, 1]               0\n","   SqueezeExcite-456         [-1, 1056, 29, 29]               0\n","          Conv2d-457          [-1, 176, 29, 29]         185,856\n","        Identity-458          [-1, 176, 29, 29]               0\n","        Identity-459          [-1, 176, 29, 29]               0\n","  BatchNormAct2d-460          [-1, 176, 29, 29]             352\n","        Identity-461          [-1, 176, 29, 29]               0\n","InvertedResidual-462          [-1, 176, 29, 29]               0\n","          Conv2d-463         [-1, 1056, 29, 29]         185,856\n","        Identity-464         [-1, 1056, 29, 29]               0\n","            SiLU-465         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-466         [-1, 1056, 29, 29]           2,112\n","          Conv2d-467         [-1, 1056, 29, 29]          26,400\n","        Identity-468         [-1, 1056, 29, 29]               0\n","            SiLU-469         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-470         [-1, 1056, 29, 29]           2,112\n","          Conv2d-471             [-1, 44, 1, 1]          46,508\n","            SiLU-472             [-1, 44, 1, 1]               0\n","          Conv2d-473           [-1, 1056, 1, 1]          47,520\n","         Sigmoid-474           [-1, 1056, 1, 1]               0\n","   SqueezeExcite-475         [-1, 1056, 29, 29]               0\n","          Conv2d-476          [-1, 176, 29, 29]         185,856\n","        Identity-477          [-1, 176, 29, 29]               0\n","        Identity-478          [-1, 176, 29, 29]               0\n","  BatchNormAct2d-479          [-1, 176, 29, 29]             352\n","        Identity-480          [-1, 176, 29, 29]               0\n","InvertedResidual-481          [-1, 176, 29, 29]               0\n","          Conv2d-482         [-1, 1056, 29, 29]         185,856\n","        Identity-483         [-1, 1056, 29, 29]               0\n","            SiLU-484         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-485         [-1, 1056, 29, 29]           2,112\n","          Conv2d-486         [-1, 1056, 29, 29]          26,400\n","        Identity-487         [-1, 1056, 29, 29]               0\n","            SiLU-488         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-489         [-1, 1056, 29, 29]           2,112\n","          Conv2d-490             [-1, 44, 1, 1]          46,508\n","            SiLU-491             [-1, 44, 1, 1]               0\n","          Conv2d-492           [-1, 1056, 1, 1]          47,520\n","         Sigmoid-493           [-1, 1056, 1, 1]               0\n","   SqueezeExcite-494         [-1, 1056, 29, 29]               0\n","          Conv2d-495          [-1, 176, 29, 29]         185,856\n","        Identity-496          [-1, 176, 29, 29]               0\n","        Identity-497          [-1, 176, 29, 29]               0\n","  BatchNormAct2d-498          [-1, 176, 29, 29]             352\n","        Identity-499          [-1, 176, 29, 29]               0\n","InvertedResidual-500          [-1, 176, 29, 29]               0\n","          Conv2d-501         [-1, 1056, 29, 29]         185,856\n","        Identity-502         [-1, 1056, 29, 29]               0\n","            SiLU-503         [-1, 1056, 29, 29]               0\n","  BatchNormAct2d-504         [-1, 1056, 29, 29]           2,112\n","          Conv2d-505         [-1, 1056, 15, 15]          26,400\n","        Identity-506         [-1, 1056, 15, 15]               0\n","            SiLU-507         [-1, 1056, 15, 15]               0\n","  BatchNormAct2d-508         [-1, 1056, 15, 15]           2,112\n","          Conv2d-509             [-1, 44, 1, 1]          46,508\n","            SiLU-510             [-1, 44, 1, 1]               0\n","          Conv2d-511           [-1, 1056, 1, 1]          47,520\n","         Sigmoid-512           [-1, 1056, 1, 1]               0\n","   SqueezeExcite-513         [-1, 1056, 15, 15]               0\n","          Conv2d-514          [-1, 304, 15, 15]         321,024\n","        Identity-515          [-1, 304, 15, 15]               0\n","        Identity-516          [-1, 304, 15, 15]               0\n","  BatchNormAct2d-517          [-1, 304, 15, 15]             608\n","InvertedResidual-518          [-1, 304, 15, 15]               0\n","          Conv2d-519         [-1, 1824, 15, 15]         554,496\n","        Identity-520         [-1, 1824, 15, 15]               0\n","            SiLU-521         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-522         [-1, 1824, 15, 15]           3,648\n","          Conv2d-523         [-1, 1824, 15, 15]          45,600\n","        Identity-524         [-1, 1824, 15, 15]               0\n","            SiLU-525         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-526         [-1, 1824, 15, 15]           3,648\n","          Conv2d-527             [-1, 76, 1, 1]         138,700\n","            SiLU-528             [-1, 76, 1, 1]               0\n","          Conv2d-529           [-1, 1824, 1, 1]         140,448\n","         Sigmoid-530           [-1, 1824, 1, 1]               0\n","   SqueezeExcite-531         [-1, 1824, 15, 15]               0\n","          Conv2d-532          [-1, 304, 15, 15]         554,496\n","        Identity-533          [-1, 304, 15, 15]               0\n","        Identity-534          [-1, 304, 15, 15]               0\n","  BatchNormAct2d-535          [-1, 304, 15, 15]             608\n","        Identity-536          [-1, 304, 15, 15]               0\n","InvertedResidual-537          [-1, 304, 15, 15]               0\n","          Conv2d-538         [-1, 1824, 15, 15]         554,496\n","        Identity-539         [-1, 1824, 15, 15]               0\n","            SiLU-540         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-541         [-1, 1824, 15, 15]           3,648\n","          Conv2d-542         [-1, 1824, 15, 15]          45,600\n","        Identity-543         [-1, 1824, 15, 15]               0\n","            SiLU-544         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-545         [-1, 1824, 15, 15]           3,648\n","          Conv2d-546             [-1, 76, 1, 1]         138,700\n","            SiLU-547             [-1, 76, 1, 1]               0\n","          Conv2d-548           [-1, 1824, 1, 1]         140,448\n","         Sigmoid-549           [-1, 1824, 1, 1]               0\n","   SqueezeExcite-550         [-1, 1824, 15, 15]               0\n","          Conv2d-551          [-1, 304, 15, 15]         554,496\n","        Identity-552          [-1, 304, 15, 15]               0\n","        Identity-553          [-1, 304, 15, 15]               0\n","  BatchNormAct2d-554          [-1, 304, 15, 15]             608\n","        Identity-555          [-1, 304, 15, 15]               0\n","InvertedResidual-556          [-1, 304, 15, 15]               0\n","          Conv2d-557         [-1, 1824, 15, 15]         554,496\n","        Identity-558         [-1, 1824, 15, 15]               0\n","            SiLU-559         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-560         [-1, 1824, 15, 15]           3,648\n","          Conv2d-561         [-1, 1824, 15, 15]          45,600\n","        Identity-562         [-1, 1824, 15, 15]               0\n","            SiLU-563         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-564         [-1, 1824, 15, 15]           3,648\n","          Conv2d-565             [-1, 76, 1, 1]         138,700\n","            SiLU-566             [-1, 76, 1, 1]               0\n","          Conv2d-567           [-1, 1824, 1, 1]         140,448\n","         Sigmoid-568           [-1, 1824, 1, 1]               0\n","   SqueezeExcite-569         [-1, 1824, 15, 15]               0\n","          Conv2d-570          [-1, 304, 15, 15]         554,496\n","        Identity-571          [-1, 304, 15, 15]               0\n","        Identity-572          [-1, 304, 15, 15]               0\n","  BatchNormAct2d-573          [-1, 304, 15, 15]             608\n","        Identity-574          [-1, 304, 15, 15]               0\n","InvertedResidual-575          [-1, 304, 15, 15]               0\n","          Conv2d-576         [-1, 1824, 15, 15]         554,496\n","        Identity-577         [-1, 1824, 15, 15]               0\n","            SiLU-578         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-579         [-1, 1824, 15, 15]           3,648\n","          Conv2d-580         [-1, 1824, 15, 15]          45,600\n","        Identity-581         [-1, 1824, 15, 15]               0\n","            SiLU-582         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-583         [-1, 1824, 15, 15]           3,648\n","          Conv2d-584             [-1, 76, 1, 1]         138,700\n","            SiLU-585             [-1, 76, 1, 1]               0\n","          Conv2d-586           [-1, 1824, 1, 1]         140,448\n","         Sigmoid-587           [-1, 1824, 1, 1]               0\n","   SqueezeExcite-588         [-1, 1824, 15, 15]               0\n","          Conv2d-589          [-1, 304, 15, 15]         554,496\n","        Identity-590          [-1, 304, 15, 15]               0\n","        Identity-591          [-1, 304, 15, 15]               0\n","  BatchNormAct2d-592          [-1, 304, 15, 15]             608\n","        Identity-593          [-1, 304, 15, 15]               0\n","InvertedResidual-594          [-1, 304, 15, 15]               0\n","          Conv2d-595         [-1, 1824, 15, 15]         554,496\n","        Identity-596         [-1, 1824, 15, 15]               0\n","            SiLU-597         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-598         [-1, 1824, 15, 15]           3,648\n","          Conv2d-599         [-1, 1824, 15, 15]          45,600\n","        Identity-600         [-1, 1824, 15, 15]               0\n","            SiLU-601         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-602         [-1, 1824, 15, 15]           3,648\n","          Conv2d-603             [-1, 76, 1, 1]         138,700\n","            SiLU-604             [-1, 76, 1, 1]               0\n","          Conv2d-605           [-1, 1824, 1, 1]         140,448\n","         Sigmoid-606           [-1, 1824, 1, 1]               0\n","   SqueezeExcite-607         [-1, 1824, 15, 15]               0\n","          Conv2d-608          [-1, 304, 15, 15]         554,496\n","        Identity-609          [-1, 304, 15, 15]               0\n","        Identity-610          [-1, 304, 15, 15]               0\n","  BatchNormAct2d-611          [-1, 304, 15, 15]             608\n","        Identity-612          [-1, 304, 15, 15]               0\n","InvertedResidual-613          [-1, 304, 15, 15]               0\n","          Conv2d-614         [-1, 1824, 15, 15]         554,496\n","        Identity-615         [-1, 1824, 15, 15]               0\n","            SiLU-616         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-617         [-1, 1824, 15, 15]           3,648\n","          Conv2d-618         [-1, 1824, 15, 15]          45,600\n","        Identity-619         [-1, 1824, 15, 15]               0\n","            SiLU-620         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-621         [-1, 1824, 15, 15]           3,648\n","          Conv2d-622             [-1, 76, 1, 1]         138,700\n","            SiLU-623             [-1, 76, 1, 1]               0\n","          Conv2d-624           [-1, 1824, 1, 1]         140,448\n","         Sigmoid-625           [-1, 1824, 1, 1]               0\n","   SqueezeExcite-626         [-1, 1824, 15, 15]               0\n","          Conv2d-627          [-1, 304, 15, 15]         554,496\n","        Identity-628          [-1, 304, 15, 15]               0\n","        Identity-629          [-1, 304, 15, 15]               0\n","  BatchNormAct2d-630          [-1, 304, 15, 15]             608\n","        Identity-631          [-1, 304, 15, 15]               0\n","InvertedResidual-632          [-1, 304, 15, 15]               0\n","          Conv2d-633         [-1, 1824, 15, 15]         554,496\n","        Identity-634         [-1, 1824, 15, 15]               0\n","            SiLU-635         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-636         [-1, 1824, 15, 15]           3,648\n","          Conv2d-637         [-1, 1824, 15, 15]          45,600\n","        Identity-638         [-1, 1824, 15, 15]               0\n","            SiLU-639         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-640         [-1, 1824, 15, 15]           3,648\n","          Conv2d-641             [-1, 76, 1, 1]         138,700\n","            SiLU-642             [-1, 76, 1, 1]               0\n","          Conv2d-643           [-1, 1824, 1, 1]         140,448\n","         Sigmoid-644           [-1, 1824, 1, 1]               0\n","   SqueezeExcite-645         [-1, 1824, 15, 15]               0\n","          Conv2d-646          [-1, 304, 15, 15]         554,496\n","        Identity-647          [-1, 304, 15, 15]               0\n","        Identity-648          [-1, 304, 15, 15]               0\n","  BatchNormAct2d-649          [-1, 304, 15, 15]             608\n","        Identity-650          [-1, 304, 15, 15]               0\n","InvertedResidual-651          [-1, 304, 15, 15]               0\n","          Conv2d-652         [-1, 1824, 15, 15]         554,496\n","        Identity-653         [-1, 1824, 15, 15]               0\n","            SiLU-654         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-655         [-1, 1824, 15, 15]           3,648\n","          Conv2d-656         [-1, 1824, 15, 15]          45,600\n","        Identity-657         [-1, 1824, 15, 15]               0\n","            SiLU-658         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-659         [-1, 1824, 15, 15]           3,648\n","          Conv2d-660             [-1, 76, 1, 1]         138,700\n","            SiLU-661             [-1, 76, 1, 1]               0\n","          Conv2d-662           [-1, 1824, 1, 1]         140,448\n","         Sigmoid-663           [-1, 1824, 1, 1]               0\n","   SqueezeExcite-664         [-1, 1824, 15, 15]               0\n","          Conv2d-665          [-1, 304, 15, 15]         554,496\n","        Identity-666          [-1, 304, 15, 15]               0\n","        Identity-667          [-1, 304, 15, 15]               0\n","  BatchNormAct2d-668          [-1, 304, 15, 15]             608\n","        Identity-669          [-1, 304, 15, 15]               0\n","InvertedResidual-670          [-1, 304, 15, 15]               0\n","          Conv2d-671         [-1, 1824, 15, 15]         554,496\n","        Identity-672         [-1, 1824, 15, 15]               0\n","            SiLU-673         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-674         [-1, 1824, 15, 15]           3,648\n","          Conv2d-675         [-1, 1824, 15, 15]          16,416\n","        Identity-676         [-1, 1824, 15, 15]               0\n","            SiLU-677         [-1, 1824, 15, 15]               0\n","  BatchNormAct2d-678         [-1, 1824, 15, 15]           3,648\n","          Conv2d-679             [-1, 76, 1, 1]         138,700\n","            SiLU-680             [-1, 76, 1, 1]               0\n","          Conv2d-681           [-1, 1824, 1, 1]         140,448\n","         Sigmoid-682           [-1, 1824, 1, 1]               0\n","   SqueezeExcite-683         [-1, 1824, 15, 15]               0\n","          Conv2d-684          [-1, 512, 15, 15]         933,888\n","        Identity-685          [-1, 512, 15, 15]               0\n","        Identity-686          [-1, 512, 15, 15]               0\n","  BatchNormAct2d-687          [-1, 512, 15, 15]           1,024\n","InvertedResidual-688          [-1, 512, 15, 15]               0\n","          Conv2d-689         [-1, 3072, 15, 15]       1,572,864\n","        Identity-690         [-1, 3072, 15, 15]               0\n","            SiLU-691         [-1, 3072, 15, 15]               0\n","  BatchNormAct2d-692         [-1, 3072, 15, 15]           6,144\n","          Conv2d-693         [-1, 3072, 15, 15]          27,648\n","        Identity-694         [-1, 3072, 15, 15]               0\n","            SiLU-695         [-1, 3072, 15, 15]               0\n","  BatchNormAct2d-696         [-1, 3072, 15, 15]           6,144\n","          Conv2d-697            [-1, 128, 1, 1]         393,344\n","            SiLU-698            [-1, 128, 1, 1]               0\n","          Conv2d-699           [-1, 3072, 1, 1]         396,288\n","         Sigmoid-700           [-1, 3072, 1, 1]               0\n","   SqueezeExcite-701         [-1, 3072, 15, 15]               0\n","          Conv2d-702          [-1, 512, 15, 15]       1,572,864\n","        Identity-703          [-1, 512, 15, 15]               0\n","        Identity-704          [-1, 512, 15, 15]               0\n","  BatchNormAct2d-705          [-1, 512, 15, 15]           1,024\n","        Identity-706          [-1, 512, 15, 15]               0\n","InvertedResidual-707          [-1, 512, 15, 15]               0\n","          Conv2d-708         [-1, 3072, 15, 15]       1,572,864\n","        Identity-709         [-1, 3072, 15, 15]               0\n","            SiLU-710         [-1, 3072, 15, 15]               0\n","  BatchNormAct2d-711         [-1, 3072, 15, 15]           6,144\n","          Conv2d-712         [-1, 3072, 15, 15]          27,648\n","        Identity-713         [-1, 3072, 15, 15]               0\n","            SiLU-714         [-1, 3072, 15, 15]               0\n","  BatchNormAct2d-715         [-1, 3072, 15, 15]           6,144\n","          Conv2d-716            [-1, 128, 1, 1]         393,344\n","            SiLU-717            [-1, 128, 1, 1]               0\n","          Conv2d-718           [-1, 3072, 1, 1]         396,288\n","         Sigmoid-719           [-1, 3072, 1, 1]               0\n","   SqueezeExcite-720         [-1, 3072, 15, 15]               0\n","          Conv2d-721          [-1, 512, 15, 15]       1,572,864\n","        Identity-722          [-1, 512, 15, 15]               0\n","        Identity-723          [-1, 512, 15, 15]               0\n","  BatchNormAct2d-724          [-1, 512, 15, 15]           1,024\n","        Identity-725          [-1, 512, 15, 15]               0\n","InvertedResidual-726          [-1, 512, 15, 15]               0\n","          Conv2d-727         [-1, 2048, 15, 15]       1,048,576\n","        Identity-728         [-1, 2048, 15, 15]               0\n","            SiLU-729         [-1, 2048, 15, 15]               0\n","  BatchNormAct2d-730         [-1, 2048, 15, 15]           4,096\n","AdaptiveAvgPool2d-731           [-1, 2048, 1, 1]               0\n","         Flatten-732                 [-1, 2048]               0\n","SelectAdaptivePool2d-733                 [-1, 2048]               0\n","          Linear-734                    [-1, 2]           4,098\n","================================================================\n","Total params: 28,344,882\n","Trainable params: 4,098\n","Non-trainable params: 28,340,784\n","----------------------------------------------------------------\n","Input size (MB): 2.38\n","Forward/backward pass size (MB): 3462.19\n","Params size (MB): 108.13\n","Estimated Total Size (MB): 3572.70\n","----------------------------------------------------------------\n"]}],"source":["#===============================================================================\n","# ▶ 모델링 코드진행\n","#===============================================================================\n","model_dict = get_model_dict(Config.num_classes)\n","model = get_transfer_model(MODEL_NAME,Config.num_classes,model_dict)\n","model = model.cuda()\n","params_to_freeze, params_to_optimizer = freeze_pretrained_model_for_classifier(model,model_dict,MODEL_NAME)\n","show_summary_of_params(model)"]},{"cell_type":"markdown","metadata":{"id":"SPyjUKAK4WWT"},"source":["# 5. 훈련 & 검증 평가\n","-------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wNrJ1Nmr4WWT"},"outputs":[],"source":["#===============================================================================\n","# ▶ [훈련함수] 설정모음\n","#===============================================================================\n","\n","# optimizer 생성\n","optimizer = optim.Adam(params_to_optimizer,Config.lerning_rate)\n","\n","# loss function 생성\n","criterion = nn.CrossEntropyLoss()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-aAedYT4WWU"},"outputs":[],"source":["#======================================================\n","# ▶ 훈련함수 정의\n","#======================================================\n","def fit(model, train_loader, val_loader):\n","    start = time()\n","    clean_memory()\n","    print('='*70)\n","\n","    # 공통 평가지표 초기화\n","    best_train_score = 0.0\n","    best_val_score = 0.0\n","    val_correct = 0.0\n","\n","    # 미니배치 트레이닝\n","    for epoch in tqdm(range(Config.epochs)):\n","        # 훈련 평가지표 초기화\n","        total_loss = 0.0\n","        n_correct = 0.0\n","\n","        # 훈련모드\n","        model.train()\n","\n","        # [훈련용] 반복추출\n","        for batch_idx, (tensor, label) in enumerate(train_loader):\n","\n","            # GPU용 검증 파라미터(CrossEntrophy)\n","            tensor = tensor.cuda()\n","            label = label.cuda()\n","\n","            # 순전파\n","            output = model(tensor)\n","            loss = criterion(output, label)\n","\n","            # 역전파\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # CrossEntrophy용 정확도(맞은갯수 예측)\n","            predicted = torch.max(model(tensor), dim=1)[1]\n","            n_correct += (predicted == label).sum()\n","\n","            # 결과 계산\n","            total_loss += loss.item()\n","            average_loss = total_loss / len(train_loader)\n","            str_train_accuracy = f'{batch_idx*Config.batch_size} / {len(train_loader.dataset)}'\n","            train_accuracy = float(n_correct * 100) / float(Config.batch_size * (batch_idx+1))\n","\n","            # 결과 출력\n","            if batch_idx % 400 == 0:\n","                print('-'*70)\n","                print(f'Epoch : {epoch}')\n","                print(f'[{str_train_accuracy}]\\t Train Accuracy(정확도):{train_accuracy:.2f}%')\n","                print(f'\\t\\t Train Average Loss (평균손실률) :{average_loss:.2f}')\n","\n","        #======================================================\n","        # ▶ 검증!\n","        #======================================================\n","        # 그래디언트 초기화\n","        with torch.no_grad():\n","\n","            # 평가모드\n","            model.eval()\n","            # 검증 평가지표 초기화\n","            val_total_loss = 0.0\n","            val_correct = 0.0\n","\n","            # [검증용] 반복추출\n","            for batch_idx, (tensor, label) in enumerate(val_loader):\n","\n","                # GPU용 검증 파라미터(CrossEntrophy)\n","                tensor = tensor.cuda()\n","                label = label.cuda()\n","\n","                # 순전파\n","                val_output = model(tensor)\n","                val_loss = criterion(val_output, label)\n","\n","                # CrossEntrophy용 정확도(맞은갯수 예측)\n","                val_predicted = torch.max(model(tensor), dim=1)[1]\n","                val_correct += (val_predicted == label).sum()\n","\n","                # 결과 계산\n","                val_total_loss += val_loss.item()\n","                val_average_loss = val_total_loss / len(val_loader)\n","                str_val_accuracy = f'{batch_idx*Config.batch_size} / {len(val_loader.dataset)}'\n","                val_accuracy = float(val_correct * 100) / float(Config.batch_size * (batch_idx+1))\n","\n","                # 결과 출력\n","                if batch_idx % 100 == 0:\n","                    print('-'*70)\n","                    print(f'Epoch : {epoch}')\n","                    print(f'[{str_val_accuracy}]\\t Validation Accuracy(정확도):{val_accuracy:.2f}%')\n","                    print(f'\\t\\t Validation Average Loss (평균손실률) :{val_average_loss:.2f}')\n","\n","        if epoch % 5 == 0 :\n","            torch.save(model.state_dict(),directory.temp_path+f'[STOPED_EPC_{epoch}]'+directory.save_model_pt_by_10_epoch_in_temp)\n","            print(f\"epoch:{epoch}\\ntemp폴더에 모델 저장 성공!\")\n","\n","\n","        print('='*70)\n","        if train_accuracy >= best_train_score:\n","            best_train_score = train_accuracy\n","            best_train_loss = average_loss\n","            print(f'Best Train Acc: {best_train_score:.2f}%')\n","            print(f'Best Train Loss: {best_train_loss:.2f}')\n","\n","        print('='*70)\n","        if val_accuracy >= best_val_score:\n","            best_val_score = val_accuracy\n","            best_val_loss = val_average_loss\n","            print(f'Best Val Acc: {best_val_score:.2f}%')\n","            print(f'Best Val Loss: {best_val_loss:.2f}')\n","\n","    print('='*70)\n","    clean_memory()\n","    end = time()\n","    print('='*70)\n","    return start, end"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1946,"status":"ok","timestamp":1702948738996,"user":{"displayName":"아돌퀘이사","userId":"14051741060385286083"},"user_tz":-540},"id":"y6R9iZFu3nT8","outputId":"c9f41dfe-a304-4465-9098-2949358b2614"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/프로젝트/[CV]개&고양이 분류/\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","message : 압축 해제가 이미 완료 되었습니다\n"]}],"source":["zipfiles = ['train.zip','test.zip']\n","extract_zipfile(zipfiles,directory.zip_path,directory.unzip_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cb77184c75734a0f9db8b68314975a1d","fbdb7ece618e46f6b06c1840c00df8ee","dcfbc3052fa247159a0c022a9dbeddee","dd993893aa714bdd9bace4b280c27d30","fb626910b16f4f4e965260d7f3c4f927","ebc39f32f8ed41f1a76edb6f884935e5","bed60bb3d2f74a96b2eb5b88d86736ae","2dc53f3e81064e33b1d5545387689b8f","d47c350defdf466bbdb49c5c57258bbf","99430d938e2f499696cdc0e7e3f544b2","a60e436d5db14207a1e4305cfef37181"]},"executionInfo":{"elapsed":14207203,"status":"error","timestamp":1702962946617,"user":{"displayName":"아돌퀘이사","userId":"14051741060385286083"},"user_tz":-540},"id":"CCQBJ1Ig4WWU","outputId":"084aee88-5feb-443c-be24-e7533647e080"},"outputs":[{"name":"stdout","output_type":"stream","text":["메모리 청소 완료\n","======================================================================\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb77184c75734a0f9db8b68314975a1d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------------\n","Epoch : 0\n","[0 / 22500]\t Train Accuracy(정확도):62.50%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 0\n","[12800 / 22500]\t Train Accuracy(정확도):88.28%\n","\t\t Train Average Loss (평균손실률) :0.39\n","----------------------------------------------------------------------\n","Epoch : 0\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 91.18%\n","Best Train Loss: 0.49\n","======================================================================\n","Best Val Acc: 96.12%\n","Best Val Loss: 0.16\n","----------------------------------------------------------------------\n","Epoch : 1\n","[0 / 22500]\t Train Accuracy(정확도):96.88%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 1\n","[12800 / 22500]\t Train Accuracy(정확도):96.50%\n","\t\t Train Average Loss (평균손실률) :0.10\n","----------------------------------------------------------------------\n","Epoch : 1\n","[0 / 2500]\t Validation Accuracy(정확도):96.88%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 96.69%\n","Best Train Loss: 0.17\n","======================================================================\n","Best Val Acc: 96.48%\n","Best Val Loss: 0.13\n","----------------------------------------------------------------------\n","Epoch : 2\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 2\n","[12800 / 22500]\t Train Accuracy(정확도):97.48%\n","\t\t Train Average Loss (평균손실률) :0.08\n","----------------------------------------------------------------------\n","Epoch : 2\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 97.47%\n","Best Train Loss: 0.13\n","======================================================================\n","Best Val Acc: 96.56%\n","Best Val Loss: 0.12\n","----------------------------------------------------------------------\n","Epoch : 3\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 3\n","[12800 / 22500]\t Train Accuracy(정확도):97.60%\n","\t\t Train Average Loss (평균손실률) :0.07\n","----------------------------------------------------------------------\n","Epoch : 3\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 97.67%\n","Best Train Loss: 0.12\n","======================================================================\n","Best Val Acc: 96.88%\n","Best Val Loss: 0.09\n","----------------------------------------------------------------------\n","Epoch : 4\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 4\n","[12800 / 22500]\t Train Accuracy(정확도):97.87%\n","\t\t Train Average Loss (평균손실률) :0.06\n","----------------------------------------------------------------------\n","Epoch : 4\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 97.87%\n","Best Train Loss: 0.10\n","======================================================================\n","Best Val Acc: 97.39%\n","Best Val Loss: 0.08\n","----------------------------------------------------------------------\n","Epoch : 5\n","[0 / 22500]\t Train Accuracy(정확도):93.75%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 5\n","[12800 / 22500]\t Train Accuracy(정확도):98.13%\n","\t\t Train Average Loss (평균손실률) :0.05\n","----------------------------------------------------------------------\n","Epoch : 5\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.07%\n","Best Train Loss: 0.09\n","======================================================================\n","Best Val Acc: 97.39%\n","Best Val Loss: 0.07\n","----------------------------------------------------------------------\n","Epoch : 6\n","[0 / 22500]\t Train Accuracy(정확도):90.62%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 6\n","[12800 / 22500]\t Train Accuracy(정확도):98.09%\n","\t\t Train Average Loss (평균손실률) :0.05\n","----------------------------------------------------------------------\n","Epoch : 6\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","======================================================================\n","Best Val Acc: 97.55%\n","Best Val Loss: 0.07\n","----------------------------------------------------------------------\n","Epoch : 7\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 7\n","[12800 / 22500]\t Train Accuracy(정확도):98.33%\n","\t\t Train Average Loss (평균손실률) :0.05\n","----------------------------------------------------------------------\n","Epoch : 7\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.33%\n","Best Train Loss: 0.08\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 8\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 8\n","[12800 / 22500]\t Train Accuracy(정확도):98.41%\n","\t\t Train Average Loss (평균손실률) :0.04\n","----------------------------------------------------------------------\n","Epoch : 8\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.33%\n","Best Train Loss: 0.08\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 9\n","[0 / 22500]\t Train Accuracy(정확도):96.88%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 9\n","[12800 / 22500]\t Train Accuracy(정확도):98.52%\n","\t\t Train Average Loss (평균손실률) :0.04\n","----------------------------------------------------------------------\n","Epoch : 9\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.45%\n","Best Train Loss: 0.06\n","======================================================================\n","Best Val Acc: 97.59%\n","Best Val Loss: 0.07\n","----------------------------------------------------------------------\n","Epoch : 10\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 10\n","[12800 / 22500]\t Train Accuracy(정확도):98.69%\n","\t\t Train Average Loss (평균손실률) :0.03\n","----------------------------------------------------------------------\n","Epoch : 10\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.52%\n","Best Train Loss: 0.05\n","======================================================================\n","Best Val Acc: 97.63%\n","Best Val Loss: 0.06\n","----------------------------------------------------------------------\n","Epoch : 11\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 11\n","[12800 / 22500]\t Train Accuracy(정확도):98.85%\n","\t\t Train Average Loss (평균손실률) :0.03\n","----------------------------------------------------------------------\n","Epoch : 11\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.61%\n","Best Train Loss: 0.05\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 12\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 12\n","[12800 / 22500]\t Train Accuracy(정확도):98.50%\n","\t\t Train Average Loss (평균손실률) :0.03\n","----------------------------------------------------------------------\n","Epoch : 12\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","======================================================================\n","Best Val Acc: 97.78%\n","Best Val Loss: 1.03\n","----------------------------------------------------------------------\n","Epoch : 13\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 13\n","[12800 / 22500]\t Train Accuracy(정확도):98.68%\n","\t\t Train Average Loss (평균손실률) :0.03\n","----------------------------------------------------------------------\n","Epoch : 13\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 14\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 14\n","[12800 / 22500]\t Train Accuracy(정확도):98.85%\n","\t\t Train Average Loss (평균손실률) :0.03\n","----------------------------------------------------------------------\n","Epoch : 14\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.73%\n","Best Train Loss: 0.05\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 15\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 15\n","[12800 / 22500]\t Train Accuracy(정확도):99.01%\n","\t\t Train Average Loss (평균손실률) :0.02\n","----------------------------------------------------------------------\n","Epoch : 15\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.77%\n","Best Train Loss: 0.04\n","======================================================================\n","Best Val Acc: 98.06%\n","Best Val Loss: 0.04\n","----------------------------------------------------------------------\n","Epoch : 16\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 16\n","[12800 / 22500]\t Train Accuracy(정확도):98.89%\n","\t\t Train Average Loss (평균손실률) :0.03\n","----------------------------------------------------------------------\n","Epoch : 16\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 17\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 17\n","[12800 / 22500]\t Train Accuracy(정확도):99.00%\n","\t\t Train Average Loss (평균손실률) :0.02\n","----------------------------------------------------------------------\n","Epoch : 17\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.82%\n","Best Train Loss: 0.05\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 18\n","[0 / 22500]\t Train Accuracy(정확도):93.75%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 18\n","[12800 / 22500]\t Train Accuracy(정확도):98.85%\n","\t\t Train Average Loss (평균손실률) :0.03\n","----------------------------------------------------------------------\n","Epoch : 18\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 19\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 19\n","[12800 / 22500]\t Train Accuracy(정확도):98.82%\n","\t\t Train Average Loss (평균손실률) :0.03\n","----------------------------------------------------------------------\n","Epoch : 19\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 20\n","[0 / 22500]\t Train Accuracy(정확도):96.88%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 20\n","[12800 / 22500]\t Train Accuracy(정확도):99.03%\n","\t\t Train Average Loss (평균손실률) :0.02\n","----------------------------------------------------------------------\n","Epoch : 20\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 21\n","[0 / 22500]\t Train Accuracy(정확도):96.88%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 21\n","[12800 / 22500]\t Train Accuracy(정확도):99.13%\n","\t\t Train Average Loss (평균손실률) :0.02\n","----------------------------------------------------------------------\n","Epoch : 21\n","[0 / 2500]\t Validation Accuracy(정확도):96.88%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.87%\n","Best Train Loss: 0.04\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 22\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 22\n","[12800 / 22500]\t Train Accuracy(정확도):99.04%\n","\t\t Train Average Loss (평균손실률) :0.02\n","----------------------------------------------------------------------\n","Epoch : 22\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 23\n","[0 / 22500]\t Train Accuracy(정확도):96.88%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 23\n","[12800 / 22500]\t Train Accuracy(정확도):99.10%\n","\t\t Train Average Loss (평균손실률) :0.02\n","----------------------------------------------------------------------\n","Epoch : 23\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 98.99%\n","Best Train Loss: 0.03\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 24\n","[0 / 22500]\t Train Accuracy(정확도):100.00%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 24\n","[12800 / 22500]\t Train Accuracy(정확도):98.89%\n","\t\t Train Average Loss (평균손실률) :0.02\n","----------------------------------------------------------------------\n","Epoch : 24\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 25\n","[0 / 22500]\t Train Accuracy(정확도):96.88%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 25\n","[12800 / 22500]\t Train Accuracy(정확도):99.15%\n","\t\t Train Average Loss (평균손실률) :0.02\n","----------------------------------------------------------------------\n","Epoch : 25\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 26\n","[0 / 22500]\t Train Accuracy(정확도):96.88%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 26\n","[12800 / 22500]\t Train Accuracy(정확도):99.20%\n","\t\t Train Average Loss (평균손실률) :0.02\n","----------------------------------------------------------------------\n","Epoch : 26\n","[0 / 2500]\t Validation Accuracy(정확도):100.00%\n","\t\t Validation Average Loss (평균손실률) :0.00\n","======================================================================\n","Best Train Acc: 99.02%\n","Best Train Loss: 0.03\n","======================================================================\n","----------------------------------------------------------------------\n","Epoch : 27\n","[0 / 22500]\t Train Accuracy(정확도):96.88%\n","\t\t Train Average Loss (평균손실률) :0.00\n","----------------------------------------------------------------------\n","Epoch : 27\n","[12800 / 22500]\t Train Accuracy(정확도):99.01%\n","\t\t Train Average Loss (평균손실률) :0.02\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-9c19599864c6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 훈련&검증 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-f7ecc8321af2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# CrossEntrophy용 정확도(맞은갯수 예측)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mn_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/_efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_pwl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/_efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mx_se\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mx_se\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx_se\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_se\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 훈련&검증 실행\n","start_time, end_time = fit(model, train_loader, val_loader)\n","get_elapsed_time(start_time,end_time)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTCOTd884WWU"},"outputs":[],"source":["#======================================================\n","# ▶ 모델저장\n","#======================================================\n","torch.save(model.state_dict(),directory.save_path+directory.save_model_pt)\n","print(\"모델 저장 성공!\")"]},{"cell_type":"markdown","metadata":{"id":"Q-fYydUb4WWU"},"source":["# 6. 예측(Inference)\n","----------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FAiMS_Jd4WWU"},"outputs":[],"source":["#======================================================\n","# ▶ 모델불러오기 (모델 아키텍쳐를동일하게 세팅)\n","#======================================================\n","model.load_state_dict(torch.load(directory.save_path+directory.save_model_pt))\n","print(\"모델 로드 성공!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XHAuRCSO4WWU"},"outputs":[],"source":["#======================================================\n","# ▶ 예측함수 정의\n","#======================================================\n","# 예측평가\n","def evaluate(model, test_loader):\n","    start = time()\n","    clean_memory()\n","    print('-'*70)\n","\n","    # 평가모드\n","    model.eval()\n","\n","    iid_list = []\n","    preds_list = []\n","\n","    # 그래디언트 초기화\n","    with torch.no_grad():\n","\n","        for img_tensor, ids in tqdm(test_loader):\n","            ch = img_tensor.shape[0]\n","            h  = img_tensor.shape[1]\n","            w  = img_tensor.shape[2]\n","            img_tensor = img_tensor.reshape(1, ch, h,w).cuda() # (1 of batch_size, channel_size, height, width)\n","            outputs = model(img_tensor)\n","            preds = F.softmax(outputs, dim=1)[:,1]\n","\n","            # 반환용 리스트\n","            iid_list.append(ids)\n","            preds_list += preds.tolist()\n","\n","    print(\"=\"*70)\n","    clean_memory()\n","    end = time()\n","    print(\"_\"*70)\n","    get_elapsed_time(start,end)\n","    return iid_list, preds_list\n","\n","# submmision제출\n","def create_and_save_submission_csv(iid_list, preds_list):\n","     submission_df = pd.DataFrame({\n","         'id': iid_list,\n","         'label': preds_list\n","     })\n","\n","     submission_df.sort_values(by='id', inplace=True)\n","     submission_df.reset_index(drop=True, inplace=True)\n","     display(submission_df)\n","     submission_df.to_csv(Directory.save_path +Directory.save_submission_csv, index=False)\n","     print('Submission 저장 완료!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bg2BoBmS4WWV"},"outputs":[],"source":["# 예측성능 채점\n","iid_list, preds_list= evaluate(model, test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"DesSrsOa4WWV"},"source":["# 7. 제출(submission)\n","------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09njOayO4WWV"},"outputs":[],"source":["# 예측결과\n","create_and_save_submission_csv(iid_list,preds_list)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[{"file_id":"1yx8A8KDWev1xG_k7qHJDd4vd1Fh2qafQ","timestamp":1702909219998},{"file_id":"1r-ZVY-5xEELTSrg38JRmGscVS02i8e_a","timestamp":1702907687102},{"file_id":"1xVDOcu6rHIdyZ5IZzSXx-QwCkEnyMuZq","timestamp":1702869332454},{"file_id":"17MlZrhZ2NvHmOfdeJ77O1JY1Z0wo4RGv","timestamp":1702868643755}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07b44212c02c4c069c93e5337d74b9c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1379683ee94645f688711fea278d8978":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13931c4558f249a28c7262c9489abc82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a621d84100534f478d4f41ade6b24d1a","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6b1ce81ab7b4b23905c479e2cadab6a","value":2}},"158afc3e0d294243beb0d36c9b17a7ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0b75188a3ee40418909db07c7a1c984","placeholder":"​","style":"IPY_MODEL_6195a244e9e542649851589f5e67c257","value":"model.safetensors: 100%"}},"2b17e999f2a740c6bc6de5f912b5243e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dc53f3e81064e33b1d5545387689b8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ad0c153dadd4429a27305e7ed467683":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb981fece6c84559bec3f0082b411509","IPY_MODEL_13931c4558f249a28c7262c9489abc82","IPY_MODEL_e01f7249c1284c51bed212fd3a2b9cca"],"layout":"IPY_MODEL_07b44212c02c4c069c93e5337d74b9c7"}},"6195a244e9e542649851589f5e67c257":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69630fd3d24d4c558d0b59e2c2cf40d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f913989d96446a091d1f2da9375e851":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73d7ec68e9f9472ea8a54aff94930ee7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1379683ee94645f688711fea278d8978","placeholder":"​","style":"IPY_MODEL_ef62ef33cde44c02bb88c1ae08c6ddf5","value":" 122M/122M [00:00&lt;00:00, 188MB/s]"}},"75247329b999457da599d1c499ba33bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86618ec5cc5e451895accb483465d9ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99430d938e2f499696cdc0e7e3f544b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0b75188a3ee40418909db07c7a1c984":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a60e436d5db14207a1e4305cfef37181":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a621d84100534f478d4f41ade6b24d1a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab3d6371d6de481e8a85ad4c60f058b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6b1ce81ab7b4b23905c479e2cadab6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bed60bb3d2f74a96b2eb5b88d86736ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf7e5d96574d4b8780f59f6ad3e1687e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86618ec5cc5e451895accb483465d9ca","max":122330162,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75247329b999457da599d1c499ba33bf","value":122330162}},"c1a476fd6a8d4a46a37513bcf5b24a5a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb77184c75734a0f9db8b68314975a1d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbdb7ece618e46f6b06c1840c00df8ee","IPY_MODEL_dcfbc3052fa247159a0c022a9dbeddee","IPY_MODEL_dd993893aa714bdd9bace4b280c27d30"],"layout":"IPY_MODEL_fb626910b16f4f4e965260d7f3c4f927"}},"d47c350defdf466bbdb49c5c57258bbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dcfbc3052fa247159a0c022a9dbeddee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dc53f3e81064e33b1d5545387689b8f","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d47c350defdf466bbdb49c5c57258bbf","value":27}},"dd993893aa714bdd9bace4b280c27d30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99430d938e2f499696cdc0e7e3f544b2","placeholder":"​","style":"IPY_MODEL_a60e436d5db14207a1e4305cfef37181","value":" 27/100 [3:56:47&lt;10:25:32, 514.14s/it]"}},"e01f7249c1284c51bed212fd3a2b9cca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab3d6371d6de481e8a85ad4c60f058b4","placeholder":"​","style":"IPY_MODEL_69630fd3d24d4c558d0b59e2c2cf40d1","value":" 2/2 [00:15&lt;00:00,  7.67s/it]"}},"eb981fece6c84559bec3f0082b411509":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b17e999f2a740c6bc6de5f912b5243e","placeholder":"​","style":"IPY_MODEL_6f913989d96446a091d1f2da9375e851","value":"100%"}},"ebc39f32f8ed41f1a76edb6f884935e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef62ef33cde44c02bb88c1ae08c6ddf5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f35833bcb4694ed8815ee2a912f0a3bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_158afc3e0d294243beb0d36c9b17a7ba","IPY_MODEL_bf7e5d96574d4b8780f59f6ad3e1687e","IPY_MODEL_73d7ec68e9f9472ea8a54aff94930ee7"],"layout":"IPY_MODEL_c1a476fd6a8d4a46a37513bcf5b24a5a"}},"fb626910b16f4f4e965260d7f3c4f927":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbdb7ece618e46f6b06c1840c00df8ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebc39f32f8ed41f1a76edb6f884935e5","placeholder":"​","style":"IPY_MODEL_bed60bb3d2f74a96b2eb5b88d86736ae","value":" 27%"}}}}},"nbformat":4,"nbformat_minor":0}
